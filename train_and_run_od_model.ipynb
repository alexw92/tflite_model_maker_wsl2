{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163f06e7",
   "metadata": {},
   "source": [
    "# Load the pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archive Images (on Server!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "tar -czvf /home/alex/all_imgs_11_10_23.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download archive from server and extract it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "scp alex@foodsnapai.com:/home/alex/all_imgs_11_10_23.tar.gz allImgs.tar.gz\n",
    "tar -xzvf allImgs.tar.gz -C /home/alex/allImgs_extracted/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load annotations without Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the value of the environment variable\n",
    "labelstudio_token = os.getenv('LABELSTUDIO_TOKEN')\n",
    "annotations_base_filename = \"annotations_test1\"\n",
    "!curl -X GET http://foodsnapai.com:8080/api/projects/1/export?exportType=CSV -H 'Authorization: Token {labelstudio_token}' --output {annotations_base_filename +\".csv\"} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert annotations and images and preprocess them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%run 'convert_csv_to_mlflow_csv.py' {annotations_base_filename +\".csv\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping automatic class merge.\n",
      "['Tomato', 'Cucumber', 'Bell-Pepper', 'Onion', 'Carrot', 'Banana', 'Egg', 'Scallion', 'Lemon', 'Potato', 'Zucchini', 'Garlic', 'Apple', 'Pumpkin', 'Ginger']\n",
      "Merging classes ['Soysauce', 'Peas', 'Oil', 'Tofu', 'Rice', 'Beans', 'Strawberry', 'Chilli', 'Lentils', 'Milk', 'Avocado', 'Spinach', 'Vinegar', 'Mango', 'Yoghurt', 'Canned-Tomato', 'Corn', 'Pasta', 'Chickpeas', 'Skyr', 'Balsamico', 'Nuts', 'Mushroom', 'Cheese', 'Plantmilk', 'Cauliflower', 'Flour', 'Broccoli', 'Orange', 'Butter', 'Curd', 'Cabagge', 'Lime', 'Eggplant', 'Salad', 'Leek'] to 'other'\n",
      "Train-test-validation split applied to annotations_test1_mlflow_shuffled.csv\n"
     ]
    }
   ],
   "source": [
    "# merge classes here\n",
    "# curret merge string: not:Tomato,Cucumber,Bell-Pepper,Onion,Carrot,Banana,Egg,Scallion,Lemon,Potato,Zucchini,Garlic,Apple,Pumpkin,Ginger\n",
    "%run 'convert_pascal_to_googlecsv.py' --merged_csv {annotations_base_filename +\"_mlflow.csv\"} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now rename the file paths in the file to their actual location (find & replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'annotations_test1_mlflow_shuffled.csv' modified with constant path replacing each file path in the second column.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Constant path to prepend\n",
    "constant_path = '/home/alex/allImgs_extracted_smaller/'\n",
    "\n",
    "# CSV file path\n",
    "csv_file_path = annotations_base_filename +\"_mlflow_shuffled.csv\"\n",
    "\n",
    "# Open the CSV file and modify the paths in the second column\n",
    "with open(csv_file_path, 'r+', newline='') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    rows = list(csv_reader)\n",
    "\n",
    "    for row in rows:\n",
    "        if len(row) > 1:  # Ensure the row has at least two columns\n",
    "            # Assuming the file path is in the second column (index 1)\n",
    "            file_path = row[1]\n",
    "            file_name = os.path.basename(file_path)  # Extract the filename from the original path\n",
    "            row[1] = os.path.join(constant_path, file_name)  # Create the new path with the constant path and filename\n",
    "\n",
    "    # Move the file pointer to the beginning\n",
    "    file.seek(0)\n",
    "\n",
    "    # Write the modified rows back to the CSV file\n",
    "    csv_writer = csv.writer(file)\n",
    "    csv_writer.writerows(rows)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' modified with constant path replacing each file path in the second column.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alex/tflite_model_maker_wsl2\n",
      "convert png image files to jpeg imgs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a74748183e64724a8c102c664ec8464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 0\n",
      "Ignored 0 files because: Not a PNG file\n",
      "Ignored 11599 files because: Not found\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "%run 'png_to_jpeg.py' {annotations_base_filename +\"_mlflow_shuffled.csv\"} \n",
    "#%run 'png_to_jpeg.py' annotations1650_mlflow_shuffled_n.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%run preproc_imgs.py /home/alex/allImgs_extracted /home/alex/allImgs_extracted_smaller 800\n",
    "#%run preproc_imgs.py /mnt/z/annotated_individual/images/ /home/alex/individual_tiny_extracted_smaller 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%run normalize_csv.py {annotations_base_filename +\"_mlflow_shuffled.csv\"}  {annotations_base_filename +\"_mlflow_shuffled_n.csv\"} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the stats of the dataset splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1709 different files in this set\n",
      "There are 16 different classes in this set\n",
      "Classes: Potato, other, Onion, Bell-Pepper, Scallion, Cucumber, Apple, Lemon, Egg, Tomato, Garlic, Banana, Carrot, Ginger, Zucchini, Pumpkin\n",
      "Potato occurs in 219 different files\n",
      "other occurs in 1468 different files\n",
      "Onion occurs in 341 different files\n",
      "Bell-Pepper occurs in 379 different files\n",
      "Scallion occurs in 277 different files\n",
      "Cucumber occurs in 428 different files\n",
      "Apple occurs in 201 different files\n",
      "Lemon occurs in 244 different files\n",
      "Egg occurs in 254 different files\n",
      "Tomato occurs in 458 different files\n",
      "Garlic occurs in 213 different files\n",
      "Banana occurs in 284 different files\n",
      "Carrot occurs in 304 different files\n",
      "Ginger occurs in 163 different files\n",
      "Zucchini occurs in 208 different files\n",
      "Pumpkin occurs in 119 different files\n",
      "\n",
      "Class Distribution in Splits:\n",
      "\n",
      "TRAIN:\n",
      "Potato: 180 files (4.02%)\n",
      "other: 1181 files (26.36%)\n",
      "Onion: 276 files (6.16%)\n",
      "Bell-Pepper: 301 files (6.72%)\n",
      "Scallion: 220 files (4.91%)\n",
      "Cucumber: 344 files (7.68%)\n",
      "Apple: 162 files (3.62%)\n",
      "Lemon: 198 files (4.42%)\n",
      "Egg: 201 files (4.49%)\n",
      "Tomato: 379 files (8.46%)\n",
      "Garlic: 181 files (4.04%)\n",
      "Banana: 221 files (4.93%)\n",
      "Carrot: 237 files (5.29%)\n",
      "Ginger: 133 files (2.97%)\n",
      "Zucchini: 172 files (3.84%)\n",
      "Pumpkin: 94 files (2.1%)\n",
      "\n",
      "TEST:\n",
      "other: 148 files (28.35%)\n",
      "Apple: 17 files (3.26%)\n",
      "Lemon: 23 files (4.41%)\n",
      "Cucumber: 38 files (7.28%)\n",
      "Egg: 25 files (4.79%)\n",
      "Bell-Pepper: 34 files (6.51%)\n",
      "Scallion: 30 files (5.75%)\n",
      "Banana: 32 files (6.13%)\n",
      "Garlic: 17 files (3.26%)\n",
      "Potato: 19 files (3.64%)\n",
      "Zucchini: 14 files (2.68%)\n",
      "Carrot: 28 files (5.36%)\n",
      "Ginger: 17 files (3.26%)\n",
      "Tomato: 40 files (7.66%)\n",
      "Onion: 30 files (5.75%)\n",
      "Pumpkin: 10 files (1.92%)\n",
      "\n",
      "VALIDATE:\n",
      "Pumpkin: 15 files (2.69%)\n",
      "other: 139 files (24.91%)\n",
      "Apple: 22 files (3.94%)\n",
      "Cucumber: 46 files (8.24%)\n",
      "Scallion: 27 files (4.84%)\n",
      "Ginger: 13 files (2.33%)\n",
      "Egg: 28 files (5.02%)\n",
      "Garlic: 15 files (2.69%)\n",
      "Tomato: 39 files (6.99%)\n",
      "Carrot: 39 files (6.99%)\n",
      "Banana: 31 files (5.56%)\n",
      "Bell-Pepper: 44 files (7.89%)\n",
      "Zucchini: 22 files (3.94%)\n",
      "Onion: 35 files (6.27%)\n",
      "Potato: 20 files (3.58%)\n",
      "Lemon: 23 files (4.12%)\n"
     ]
    }
   ],
   "source": [
    "%run 'get_label_stats.py' {annotations_base_filename +\"_mlflow_shuffled_n.csv\"} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can start to load the model and train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba09f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "model_name = 'efficientdet-lite0'\n",
    "epochs = 50\n",
    "batch_size = 4\n",
    "model_dir = 'models/'+model_name+'/'+'new_model_1700'+'_e'+str(epochs)+'_b'+str(batch_size)\n",
    "#spec = model_spec.get('efficientdet_lite1')\n",
    "spec = object_detector.EfficientDetLite0Spec(\n",
    "    model_name = model_name,\n",
    "    model_dir='/home/alex/checkpoints_lite0_1700imgs/',\n",
    "    hparams='grad_checkpoint=true,strategy=gpus',\n",
    "    epochs=epochs, batch_size=batch_size,\n",
    "    steps_per_execution=1, moving_average_decay=0,\n",
    "    var_freeze_expr='(efficientnet|fpn_cells|resample_p6)',\n",
    "    tflite_max_detections=25\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26b4f5",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ad66896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/alex/tflite_model_maker_wsl2\n",
      "The file '/home/alex/tflite_model_maker_wsl2/annotations_test1_mlflow_shuffled_n.csv' exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_directory)\n",
    "file_path = '/home/alex/tflite_model_maker_wsl2/'+annotations_base_filename +\"_mlflow_shuffled_n.csv\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"The file '{file_path}' exists.\")\n",
    "train_data, validation_data, test_data = object_detector.DataLoader.from_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ce5fa6",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = object_detector.create(train_data, model_spec=spec, batch_size=4, train_whole_model=True, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the model maker class list to a file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "label_map = model.model_spec.config.label_map.as_dict()\n",
    "# Writing the dictionary to a JSON file\n",
    "with open(model_dir+'/label_map.json', 'w') as file:\n",
    "    json.dump(label_map, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run tensorboard to monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-19 00:27:54.036765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-19 00:27:54.073041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-19 00:27:54.073123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "E1119 00:27:54.866138 140349614286656 program.py:298] TensorBoard could not bind to port 6006, it was already in use\n",
      "ERROR: TensorBoard could not bind to port 6006, it was already in use\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=/home/alex/checkpoints_lite1_1700imgs/ --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4952ee",
   "metadata": {},
   "source": [
    "Run on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18520724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 7s 125ms/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AP': 0.1256359,\n",
       " 'AP50': 0.18864998,\n",
       " 'AP75': 0.14579509,\n",
       " 'APs': 0.0,\n",
       " 'APm': 0.0941844,\n",
       " 'APl': 0.14089024,\n",
       " 'ARmax1': 0.115081616,\n",
       " 'ARmax10': 0.2126694,\n",
       " 'ARmax100': 0.21943912,\n",
       " 'ARs': 0.0,\n",
       " 'ARm': 0.1737192,\n",
       " 'ARl': 0.24223559,\n",
       " 'AP_/Potato': 0.08731195,\n",
       " 'AP_/other': 0.23187979,\n",
       " 'AP_/Onion': 0.15317023,\n",
       " 'AP_/Bell-Pepper': 0.2184473,\n",
       " 'AP_/Scallion': 0.11563398,\n",
       " 'AP_/Cucumber': 0.16958745,\n",
       " 'AP_/Apple': 0.0038759527,\n",
       " 'AP_/Lemon': 0.0698714,\n",
       " 'AP_/Egg': 0.36860254,\n",
       " 'AP_/Tomato': 0.15523179,\n",
       " 'AP_/Garlic': 0.010900743,\n",
       " 'AP_/Banana': 0.29010698,\n",
       " 'AP_/Carrot': 0.046379015,\n",
       " 'AP_/Ginger': 6.0006e-05,\n",
       " 'AP_/Zucchini': 0.013992164,\n",
       " 'AP_/Pumpkin': 0.07512333}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ae545d",
   "metadata": {},
   "source": [
    "### Export the model to tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a168367b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 19:45:19.106179: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2023-11-19 19:45:32.672745: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 3 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 1.804 G  ops, equivalently 0.902 G  MACs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 19:45:36.814122: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2023-11-19 19:45:36.814162: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2023-11-19 19:45:36.814653: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpjzlam0sf\n",
      "2023-11-19 19:45:36.871303: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2023-11-19 19:45:36.871329: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmpjzlam0sf\n",
      "2023-11-19 19:45:37.076689: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-11-19 19:45:38.070630: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpjzlam0sf\n",
      "2023-11-19 19:45:38.511198: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1696547 microseconds.\n",
      "2023-11-19 19:45:39.369564: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-19 19:45:40.250569: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.804 G  ops, equivalently 0.902 G  MACs\n",
      "\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 0\n",
      "2023-11-19 19:46:49.997482: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.804 G  ops, equivalently 0.902 G  MACs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 1.804 G  ops, equivalently 0.902 G  MACs\n"
     ]
    }
   ],
   "source": [
    "model.export(export_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d704b3",
   "metadata": {},
   "source": [
    "Run inference script for visual output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0344fa93",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# needs to be after training for some reason\n",
    "\n",
    "%run 'png_to_jpeg.py' {annotations_base_filename +\"_mlflow_shuffled_n.csv\"}\n",
    "\n",
    "\n",
    "%run do_inference.py --input_csv {annotations_base_filename +\"_mlflow_shuffled_n.csv\"}\\\n",
    "                       --model_url {model_dir}/model.tflite --output_dir output_inference1 --label_file {model_dir}/label_map.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
