{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163f06e7",
   "metadata": {},
   "source": [
    "# Load the pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archive Images (on Server!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "tar -czf /home/alex/all_imgs_07_01_24.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download archive from server and extract it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_imgs.tar.gz                             100%  871MB  92.8MB/s   00:09    \n",
      "3392d64b-75eefce8689d7102_IMG_20230802_203236.jpg\n",
      "5e332ce9-155350565f93ada7_IMG_20240107_155443_HDR.jpg\n",
      "99256d4c-f9c2d351859657e9_IMG_20240107_161850_HDR.jpg\n",
      "063a06c6-d04ff2f1599c141c_IMG_20240107_161941_HDR.jpg\n",
      "c3e72227-b7bee88fca68a47f_IMG_20240107_155226_HDR.jpg\n",
      "09776733-839cc2913cb02ca3_EAA45F81-CAA1-41EF-BA7A-FDF3014AAD4D.jpeg\n",
      "25dbc8bd-76da42e358d6a6e6_IMG_20240107_154152_HDR.jpg\n",
      "05885819-da097dd25bd1765e_1000057480.jpg\n",
      "a6e3be64-9d27ec8516a7c88d_1000057234.jpg\n",
      "05184788-cb96bc02bbbfb32e_IMG_20240107_155408_HDR.jpg\n",
      "246c9f39-967d5bef481efb1c_20231110_150444.jpg\n",
      "78bcf2cc-1cd8087115a0ca03_1000057237.jpg\n",
      "84eec4d9-2afa9b824f72748b_1000057231.jpg\n",
      "f4075a96-8cf891546d9caeff_1000057534.jpg\n",
      "bfff1e13-4a20450a838047ef_IMG_20240107_161535_HDR.jpg\n",
      "e192e64b-56f16cbb4ac468fa_IMG-20230720-WA0026.jpg\n",
      "84feaee6-75f8a3e4f414aa32_1000057587.jpg\n",
      "c828593d-e8eb24d9a9110084_1000057484.jpg\n",
      "577cb0ba-8b89acaf11819231_1000057540.jpg\n",
      "d0f638c8-5190b17234de5884_20231012_115811.jpg\n",
      "a682b90b-59febfdaaba3b3ae_IMG_20240107_161649_HDR.jpg\n",
      "24512590-1eb4787248c45201_1000057591.jpg\n",
      "1f3d4b87-81f76d577bd2e1b4_1000057589.jpg\n",
      "8679cb0f-aff545b9210b76ca_1000057314.jpg\n",
      "e09214d3-5ace616220952d8e_IMG_20240107_161218_HDR.jpg\n",
      "0ea7e403-48c611acbd605459_IMG_9951.jpeg\n",
      "efc834ad-72b3e3f9d9cb1b59_1000057595.jpg\n",
      "01023ed7-848852b9ace0a7d6_IMG_20240107_161725_HDR.jpg\n",
      "e3062fa0-93e7cef434753ad4_1000057607.jpg\n",
      "47a6c851-30bed66d32986591_1000057486.jpg\n",
      "d431164c-2c6c1624c9afd243_IMG_20240107_162144_HDR.jpg\n",
      "523033e8-bae04783b2483347_1000057606.jpg\n",
      "1f00d8a6-216afcad608bd554_1000057553.jpg\n",
      "46be20e6-62c618ef4cce73d0_IMG_20240107_161207_HDR.jpg\n",
      "74329a0a-e9624a1dd90c79b8_IMG_20240107_162318_HDR.jpg\n",
      "a2a16c75-c86e6e7497c099f5_1000057238.jpg\n",
      "b0806426-c1c968a45741e810_IMG_20240107_155213_HDR.jpg\n",
      "d9db34aa-938221d6b8591f80_1000057552.jpg\n",
      "335c8588-10c4bbacff1f17c8_88075BFB-5E6C-4F66-A09C-12F76341C077.jpeg\n",
      "8ab6bf3a-0f9eb1f281a5c8bd_1000057122.jpg\n",
      "05598d11-7034009d02ce9fec_IMG_20240107_162341_HDR.jpg\n",
      "cfd92401-42f5d275c8d76f01_1000057074.jpg\n",
      "6e7500ba-9f07c3c119040da8_16892269686205927986710142714597.jpg\n",
      "6893fc19-f62c0ff1280129f9_IMG_20240107_161742_HDR.jpg\n",
      "1bf5d978-6aa0474c4fd8c892_IMG_20240107_160813_HDR.jpg\n",
      "1de30aeb-acf4aeca10192319_1000057601.jpg\n",
      "c1163658-7638e7c8382816f7_IMG_20240107_160920_HDR.jpg\n",
      "646c4469-600d80ac3ce3fb00_IMG_20240107_161146_HDR.jpg\n",
      "e9740f95-c56d4a8431d5ae1e_1000057341.jpg\n",
      "07c3fc8d-a142edcdeb1a45da_1000057342.jpg\n",
      "2fed3595-0e2b1b0ade1e9b5b_IMG_20240107_161835_HDR.jpg\n",
      "e4708567-b2ff3fb2f9a45439_IMG-20230713-WA0067.jpg\n",
      "358a35b3-2c05dcc00426a692_IMG_20240107_161817_HDR.jpg\n",
      "58131c75-b3e7cb5bfd5ee9ec_IMG-20230715-WA0013.jpg\n",
      "5f75809f-1ecb980f9d45baae_1000057585.jpg\n",
      "4802c328-fa8f11524c6af777_IMG_20240107_162044_HDR.jpg\n",
      "90f88af6-beb27c9cf3dd0db8_1000057232.jpg\n",
      "cd777026-3db41362ccdf3481_IMG_20240107_160831_HDR.jpg\n",
      "33a7ecec-f3e8a3c982fa73de_20230713_065603.jpg\n",
      "e73492a1-5802632428dffdee_IMG_20240107_160933_HDR.jpg\n",
      "66f65042-21c6e082d203713b_E0B9F063-9F2C-467A-916A-A9F83DA2F1E9.jpeg\n",
      "cc8e5bdb-fc9822ae94d078b3_1000057075.jpg\n",
      "39f98f22-31c70c7449ca0121_1000057019.jpg\n",
      "7aa71ef9-b479f2c4493bf855_1000057313.jpg\n",
      "bcf9c47b-a74dde3c90562275_IMG_20240107_161120_HDR.jpg\n",
      "992fdb6b-faac245dcc3e1839_1000057590.jpg\n",
      "68e2127d-086b8b611607a350_1000057121.jpg\n",
      "210848ad-b654610e0dfe9799_1000057561.jpg\n",
      "45fdbdf2-3b30457e1909a9a2_1000057124.jpg\n",
      "bf06ff78-77660ee197eb99f6_1000057282.jpg\n",
      "802be060-f2bdebecb3a05502_1000057557.jpg\n",
      "3e64e271-f3c3e389f7edafec_1000057584.jpg\n",
      "5cbe02b2-7ac8738d91b0c359_1000057283.jpg\n",
      "93fbbfa7-433e8b432425402b_1000057479.jpg\n",
      "7c0d5581-a9f4ca69579c1833_1000057478.jpg\n",
      "3b45c85f-407ffc694584ab91_1000057072.jpg\n",
      "003cd074-e70e040d951515e6_1000057069.jpg\n",
      "92d5d2fd-6e7072304a982feb_IMG_20240107_161449_HDR.jpg\n",
      "53a750c4-3a3b45cba0acb91a_1000057610.jpg\n",
      "824904b1-a5e72497ce9bdc28_IMG_20240107_155144_HDR.jpg\n",
      "17d02858-8dedf3f428108d3a_1000057358.jpg\n",
      "96eea0ef-49da8e811d3a5e4d_1000057598.jpg\n",
      "0c1dcb59-4d3dec0158dacd4f_16877178506334418547235422419011.jpg\n",
      "7645894b-3328b4524c878f3b_IMG_20240107_155158_HDR.jpg\n",
      "9171d077-7b085769c9d164d2_IMG_20240107_161240_HDR.jpg\n",
      "3fe95dbc-b06ab4b49f04174e_IMG-20230713-WA0068.jpg\n",
      "41f50411-1e76a91d9865600b_1000057359.jpg\n",
      "c6ee818f-15753e9860fb239c_3B15F003-DD2C-4C5C-B65F-3AD2AEDE3181.jpeg\n",
      "4d3e37ba-4a54edbb5627642d_1000057586.jpg\n",
      "489ce777-ceac2d4e5474a167_1000057356.jpg\n",
      "81067173-6e209cbed92eb466_IMG_9950.jpeg\n",
      "731c7754-d7c30c96150ce5df_1000057562.jpg\n",
      "dbe25984-91d37c59d57ba7f9_IMG_20240107_155524_HDR.jpg\n",
      "f412162c-7bf8d1e5a60957f9_IMG_20240107_161613_HDR.jpg\n",
      "679261e2-fe42bb0250f5cbb2_1000057554.jpg\n",
      "02ad09e3-da9370df796abbef_1000057583.jpg\n",
      "168555d1-c0ff0be1d9373d50_1000057021.jpg\n",
      "afd63d2b-a417deff2883fb75_1000057126.jpg\n",
      "b8bb231b-b8c53279a383c73a_1000057115.jpg\n",
      "4975c6ab-7b059c6deaed6743_1000057472.jpg\n",
      "c7df890a-7734ab9fc7c4e939_IMG_20240107_161009_HDR.jpg\n",
      "a34a19ec-a71612cb59b9bc60_IMG_9953.jpeg\n",
      "fa7b8151-739d55e36512b842_IMG_20240107_155325_HDR.jpg\n",
      "de188a82-ab6c355e4d1e2e01_1000057120.jpg\n",
      "59d5f27a-f3f95e2e32b9ef08_IMG_20240107_154235_HDR.jpg\n",
      "678d65b9-04d643853cd18a53_0FCEA947-6201-4BEA-941E-ABD7BBB0DC0F.jpeg\n",
      "61f14d28-83c1dabecd9d3337_1000057073.jpg\n",
      "355f3828-e3c92c41b4ec7b54_IMG_20240107_155348_HDR.jpg\n",
      "d473990c-06d39e8cf92e371f_IMG_20240107_160952_HDR.jpg\n",
      "2613cd8c-e3121a43f4182bd6_1000057114.jpg\n",
      "a87ee8f7-79018f136738d025_1000057470.jpg\n",
      "fb4a17b2-4084b804569e8460_1000057581.jpg\n",
      "c7665438-9c33bcb5a5e1b441_1000057603.jpg\n",
      "9c729316-ff5a486f10125e3c_IMG_20240107_161418_HDR.jpg\n",
      "03b42e0b-0ed40ddb527ab28d_1000057488.jpg\n",
      "69fb45bd-85f1d1d89dc12a5d_1000057558.jpg\n",
      "f7aa9be7-881a024a6871a1da_IMG_20240107_162355_HDR.jpg\n",
      "43b589c2-1d76af0674304f64_1000057476.jpg\n",
      "58a60183-c509e610699b7495_6F10D115-6151-4585-89F6-B814D4CD768D.jpeg\n",
      "73b900f1-7e7088d4cc72a46f_1000057435.jpg\n",
      "509a5d29-101e2c57772cf601_1000057468.jpg\n",
      "2833a0cf-9f7580301970752e_1000057344.jpg\n",
      "755936fa-70993c27f0bbd082_IMG_20240107_162518_HDR.jpg\n",
      "e6ada1a7-7d4fd6c247de8828_1000057609.jpg\n",
      "71c4c25e-9f387afda9d1d62a_C6D25A00-48C8-4D85-8B91-05CB60552659.jpeg\n",
      "afc3da0d-2663a116189a0d1d_1000057339.jpg\n",
      "fb8bf49d-b3845b32402a0c7a_1000057485.jpg\n",
      "9e1d2c5c-0a7a9facafaf7d51_4E0189C3-35D4-47F7-9D69-6133DF19AC52.jpeg\n",
      "d2cce1ba-7440a68464ef65a1_1000057474.jpg\n",
      "8eba65da-52facf87a8aaa161_IMG_20240107_161758_HDR.jpg\n",
      "4b6a3039-e7ac10f144781c12_1000057475.jpg\n",
      "9b36e196-1a7edf83ad70a52e_1000057536.jpg\n",
      "3b2bc726-2d05e753b66283e7_IMG_20240107_155251_HDR.jpg\n",
      "cfcadef0-9632ad4ec7ff3da1_IMG_20230723_151956.jpg\n",
      "7c648743-72abe5975aef469b_1000057017.jpg\n",
      "67374e4b-46e1ccac80548dfb_1000057537.jpg\n",
      "8ad93998-bce480550c285bf8_IMG_20240107_161132_HDR.jpg\n",
      "3c8da1b1-67cb73a4145cfb5c_1000057471.jpg\n",
      "c5ce0585-77583589ff88d649_IMG_20240107_162030_HDR.jpg\n",
      "d5cca17f-43ce59b489d86516_1000057602.jpg\n",
      "41b4d104-2e29403209cb4abd_1000057235.jpg\n",
      "61ddc7cd-3576b3a86fa3540c_IMG_20240107_160741_HDR.jpg\n",
      "45706e4f-7740f3b12446ce6d_1000057469.jpg\n",
      "fd925533-4e3d9ef033be5a0f_IMG_20240107_161630_HDR.jpg\n",
      "181988a5-ebf74c91ddfbd18a_1000057116.jpg\n",
      "3ac709fe-61f1195a35b799e3_IMG_20240107_161321_HDR.jpg\n",
      "c8aedb5f-1a2a64de9f793bce_1000057340.jpg\n",
      "996df199-075af0747bb77a51_IMG_20240107_154304_HDR.jpg\n",
      "6debee06-8f08992a31d56e0b_IMG_20240107_161918_HDR.jpg\n",
      "35f9d27a-5bf374b6231432b5_1000057608.jpg\n",
      "f98c3c8c-76dd8afe62a7a7f6_IMG_20240107_162129_HDR.jpg\n",
      "b58f8cc3-829c9b221708c4a3_1000057555.jpg\n",
      "fca15136-79824ea867cdf9be_1000057482.jpg\n",
      "c9878d4a-0723d1027cf2e9aa_1000057599.jpg\n",
      "1fad4b01-7cc1eebed8e26e4a_1000057070.jpg\n",
      "b267ea3b-c2576be86ec2146d_1000057018.jpg\n",
      "9b0eaaf0-e1113eb3e407f78e_379A3DBA-D0A5-4B6F-BE36-14E5BA8C6F45.jpeg\n",
      "f88a7012-cdd424ff004234f4_1000057437.jpg\n",
      "c1583391-5d5784af8a59c045_1000057022.jpg\n",
      "ad36bd3c-acb6e6409b50ecbe_1000057020.jpg\n",
      "22a64460-ffd8de8acaaf90b0_1000057436.jpg\n",
      "9415a97f-bc13330ae59c35eb_1000057596.jpg\n",
      "76afb212-d110349cf647a213_IMG_20240107_161101_HDR.jpg\n",
      "ad7ad5ee-9ef893d5417453c8_7B1DE51C-8053-44D0-8256-3DD72C5A1FDD.jpeg\n",
      "8a1b6f95-7c632a979569c527_1000057487.jpg\n",
      "10de555e-42880e13261c83e3_20231110_150519.jpg\n",
      "37cd26af-5669011ff65e9c49_IMG_20240107_155711_HDR.jpg\n",
      "91023d35-fd14e7ac6dda81b5_IMG_20240107_155616_HDR.jpg\n",
      "83dff0ef-7c84793fb6e409ca_39A0C66A-E17A-49A7-828B-185E2FED6506.jpeg\n",
      "2c0a3679-bc3b4370347ed16f_IMG_20240107_161515_HDR.jpg\n",
      "c1dbc8a1-8c5dc347d9e73a1f_FF8533F3-0EE7-4F71-89FF-4ACDE438A3C6.jpeg\n",
      "85272474-393fcf7aa7038297_1000057477.jpg\n",
      "eb321a27-e1e44d3a4af41a6b_IMG_20240107_160852_HDR.jpg\n",
      "057c9ba0-b5a5ec112bc3d1e4_IMG_20240107_155753_HDR.jpg\n",
      "d07f118e-a071a66582e38762_1000057580.jpg\n",
      "c7156150-28df191f7b27245d_1000057315.jpg\n",
      "53f9e060-85e2dd708c4be0ab_IMG_20240107_154202_HDR.jpg\n",
      "7abd397f-56d1a3425e13bae1_IMG_20240107_161040_HDR.jpg\n",
      "d60c1aa9-7a26016c22fc5b4b_IMG_20240107_162101_HDR.jpg\n",
      "b15e62d3-e434b0478af581fc_1000057357.jpg\n",
      "a7ddfd9d-df01b5debcbefe13_20231012_115639.jpg\n",
      "714b6c54-802a5d2fbf46e581_IMG_20240107_161559_HDR.jpg\n",
      "5cc3d212-db88c35aa00af692_IMG_20240107_154351_HDR.jpg\n",
      "58e56567-65778bff66c9a385_3618AA8B-2D18-44A2-B5A2-A602111E4AB4.jpeg\n",
      "d3a8ca94-41b3a8ba7f5735d6_1000057600.jpg\n",
      "fcaf2e05-35343c488f37f6e3_1000057564.jpg\n",
      "1e4078c9-078c5243bea765a1_IMG_20230729_142139.jpg\n",
      "ae370432-debe48420ed06f9f_IMG_20240107_162216_HDR.jpg\n",
      "a178cfbc-d874e244465f9f2a_20230829_101802.jpg\n",
      "bc15447c-0ba7880025476f22_1A7AB569-EAEC-461A-B92F-8909259B2CD1.jpeg\n",
      "9552d8f2-057577eb737bd13b_1000057559.jpg\n",
      "99d4d6e9-48b0a5e0fed75134_1000057588.jpg\n",
      "10855742-379753cb26098080_1000057473.jpg\n",
      "f76efb0b-44bdfc9c8b0431de_1000057535.jpg\n",
      "dfe1715e-f1566e5cb768b4a3_1000057489.jpg\n",
      "badc234c-fa03b8714c32f1a5_1000057360.jpg\n",
      "791ec032-1a13200ccb6636fa_20231012_115536.jpg\n",
      "17ab2662-8cbe9b567f172831_1000057071.jpg\n",
      "d08f022b-ccbd4d86a30f3ab0_IMG_20240107_155052_HDR.jpg\n",
      "edcea7b5-f559b8778e091b7a_IMG_20240107_155640_HDR.jpg\n",
      "bc4752d7-51d71d6d2191be0c_1000057343.jpg\n",
      "83e62d6a-f913018974e38b21_1000057241.jpg\n",
      "29403632-6734496887ce2a84_IMG_20240107_161905_HDR.jpg\n",
      "5552935b-3bb61161cb8804fc_IMG_9954.jpeg\n",
      "50ebaa18-c79e86fb986cc0d4_1000057481.jpg\n",
      "35bde5ac-a19074fb9603e3c4_1000057593.jpg\n",
      "4e6ed3ab-89f2d3a2ef217b26_F2275458-540D-4DDA-9601-C8F24BD0365C.jpeg\n",
      "043662bf-14e49f5a4a2e24ec_IMG_20240107_162233_HDR.jpg\n",
      "a5d06977-fcefd796156abe78_1000057240.jpg\n",
      "073d1f34-3865fa3a65629b08_IMG_20240107_161546_HDR.jpg\n",
      "0fa8ae2a-ed15a98a3285e17a_1000057236.jpg\n",
      "743427c0-ab3a9771d523ebc6_1000057605.jpg\n",
      "caefa123-d42b4d972dc2775d_IMG_20240107_161404_HDR.jpg\n",
      "13f11575-fda8285ae7de4098_1000057597.jpg\n",
      "02173c3c-8f5d7cd7d994b9e7_IMG_9952.jpeg\n",
      "5380d248-7ccf7163153b8d9c_IMG_20240107_162251_HDR.jpg\n",
      "4fa246a3-437a77f5c7abc466_20230720_191419.jpg\n",
      "7d845ad8-f474aaa9ccaf4dd9_1000057016.jpg\n",
      "07f84cbe-8ea972f8f32846e0_1000057125.jpg\n",
      "ebc6ecdc-f4828f3d9c12db12_IMG_9955.jpeg\n",
      "0464d072-3895ac15b8a1d46b_IMG_20240107_161342_HDR.jpg\n",
      "0751af07-ddd1d77c29742daf_IMG_20240107_161705_HDR.jpg\n",
      "9878457d-6de47953807586d9_1000057233.jpg\n",
      "3da87793-cafdf27204f4298a_1000057539.jpg\n",
      "28339df0-e69651b9d24af9dc_IMG_20240107_161029_HDR.jpg\n",
      "15668436-8788a3249def2bee_1000057556.jpg\n",
      "de3a4447-42cd36cc6ee0cf53_IMG_20240107_154226_HDR.jpg\n",
      "e1409273-b22177577f690f19_1000057316.jpg\n",
      "a4fbfdef-bc5fdfc4c769bb78_1000057611.jpg\n",
      "4f3a4656-f04a87fa9e22c5b9_20231130_150805.jpg\n",
      "b1d06145-f3d8c42d5902b822_1000057239.jpg\n",
      "75af2550-db504524ebbcfe82_1000057117.jpg\n",
      "97a1420b-adc98c53c32a938b_IMG_20240107_162156_HDR.jpg\n",
      "0c70be64-618ed9dce7558a0d_IMG_20240107_155114_HDR.jpg\n",
      "1cb48f9e-5bb315e013f27549_1000057578.jpg\n",
      "839b829c-df036142f3169223_1000057538.jpg\n",
      "45b4ae83-e2a78e9134be6c4a_5B546CD3-D6B4-4A2E-8147-A683170374A9.jpeg\n",
      "5c8cb161-b821757c4b93225e_IMG_20240107_155136_HDR.jpg\n",
      "c805d9a3-6ba0ff08bd7dafeb_1000057317.jpg\n",
      "5d71be29-32e9a7969710adbb_1000057582.jpg\n",
      "5d59053c-0ae1370922ef9599_1000057594.jpg\n",
      "7ef698f3-f061d548ac8c9d9e_1000057604.jpg\n",
      "d2b4d943-cd245cf66392ee38_1000057483.jpg\n",
      "9aab2282-633801ec8fa1281f_1000057592.jpg\n",
      "399259b0-3223bdd0c7522965_IMG_20240107_154248_HDR.jpg\n",
      "02610ac2-f29b485313988135_IMG_20240107_161430_HDR.jpg\n",
      "3e66ad21-673d52abc0cf96ad_IMG_20240107_162303_HDR.jpg\n",
      "f7c2ac4d-00c2502cd0ad87e3_1000057579.jpg\n",
      "e6313245-0c8e4bb1d3ef3960_IMG_20240107_162011_HDR.jpg\n",
      "29398559-0eece77ff8af1d63_1000057119.jpg\n",
      "33ce7b77-c026a2d2ce287c95_1000057541.jpg\n",
      "2bc00870-3af3cfe0b33a8aaa_1000057563.jpg\n"
     ]
    }
   ],
   "source": [
    "!scp alex@foodsnapai.com:/home/alex/delta_imgs.tar.gz /home/alex/delta_imgs.tar.gz\n",
    "!tar -xzf /home/alex/delta_imgs.tar.gz -C /home/alex/allImgs_extracted/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load annotations without Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations/single_annotations.csv\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 4168k  100 4168k    0     0   341k      0  0:00:12  0:00:12 --:--:-- 1043k\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the value of the environment variable\n",
    "labelstudio_token = os.getenv('LABELSTUDIO_TOKEN')\n",
    "annotations_dir = \"annotations/\"\n",
    "filename = \"single_annotations\"\n",
    "file_path = os.path.join(annotations_dir, filename + \".csv\")\n",
    "project_id_single_groceries=4\n",
    "project_id_mixed_groceries=1\n",
    "!echo {file_path} \n",
    "!curl http://foodsnapai.com:8080/api/projects/1/export?exportType=CSV -H 'Authorization: Token {labelstudio_token}' --output {file_path} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert annotations and images and preprocess them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct files in dataset: 2709\n",
      "File renamed to: annotations/single_annotations_2709_mlflow.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "%run 'convert_csv_to_mlflow_csv.py' {file_path} \n",
    "\n",
    "mlflow_filename = os.path.join(annotations_dir, filename + \"_mlflow.csv\") \n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(mlflow_filename)\n",
    "\n",
    "# Count distinct values in the 'path' column\n",
    "distinct_files = df['path'].unique()\n",
    "num_distinct_files = len(distinct_files)\n",
    "\n",
    "# Rename the file to include the number of images\n",
    "base_name, extension = os.path.splitext(filename)\n",
    "new_filename =os.path.join(annotations_dir, f\"{filename}_{num_distinct_files}_mlflow.csv\") \n",
    "os.rename(mlflow_filename, new_filename)\n",
    "\n",
    "print(f\"Distinct files in dataset: {num_distinct_files}\")\n",
    "print(f\"File renamed to: {new_filename}\")\n",
    "annotations_full_filename = new_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping automatic class merge.\n",
      "['Tomato', 'Cucumber', 'Bell-Pepper', 'Onion', 'Carrot', 'Banana', 'Egg', 'Scallion', 'Lemon', 'Potato', 'Zucchini', 'Garlic', 'Apple', 'Pumpkin', 'Ginger', 'Lime', 'Avocado', 'Mango', 'Broccoli', 'Chilli', 'Cauliflower', 'Eggplant', 'Cabagge', 'Orange']\n",
      "Merging classes ['Canned-Tomato', 'Cheese', 'Lentils', 'Curd', 'Yoghurt', 'Beans', 'Peas', 'Leek', 'Salad', 'Strawberry', 'Skyr', 'Oil', 'Plantmilk', 'Spinach', 'Mushroom', 'Tofu', 'Rice', 'Corn', 'Vinegar', 'Soysauce', 'Balsamico', 'Butter', 'Chickpeas', 'Nuts', 'Pasta', 'Milk', 'Flour'] to 'other'\n",
      "Train-test-validation split applied to annotations/single_annotations_2709_mlflow_shuffled.csv\n"
     ]
    }
   ],
   "source": [
    "# merge classes here\n",
    "# curret merge string: not:Tomato,Cucumber,Bell-Pepper,Onion,Carrot,Banana,Egg,Scallion,Lemon,Potato,Zucchini,Garlic,Apple,Pumpkin,Ginger\n",
    "# not:Tomato,Cucumber,Bell-Pepper,Onion,Carrot,Banana,Egg,Scallion,Lemon,Potato,Zucchini,Garlic,Apple,Pumpkin,Ginger,Lime,Avocado,Mango,Broccoli,Chilli,Cauliflower,Eggplant,Cabagge,Orange\n",
    "# annotations_full_filename = \"annotations_single\"    +\"_mlflow.csv\"\n",
    "%run 'convert_pascal_to_googlecsv.py' --merged_csv {annotations_full_filename} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now rename the file paths in the file to their actual location (find & replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'annotations/single_annotations_2709_mlflow_shuffled.csv' modified with constant path replacing each file path in the second column.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Constant path to prepend\n",
    "constant_path = '/home/alex/allImgs_extracted_smaller/'\n",
    "\n",
    "# CSV file path\n",
    "csv_dir, csv_filename = os.path.split(annotations_full_filename)\n",
    "csv_base, csv_ext = os.path.splitext(csv_filename)\n",
    "# add shuffled suffix because convert_pascal_to_googlecsv.py appends this\n",
    "csv_file_path = os.path.join(csv_dir, f\"{csv_base}_shuffled{csv_ext}\")\n",
    "\n",
    "# Open the CSV file and modify the paths in the second column\n",
    "with open(csv_file_path, 'r+', newline='') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    rows = list(csv_reader)\n",
    "\n",
    "    for row in rows:\n",
    "        if len(row) > 1:  # Ensure the row has at least two columns\n",
    "            # Assuming the file path is in the second column (index 1)\n",
    "            img_file_path = row[1]\n",
    "            img_file_name = os.path.basename(img_file_path)  # Extract the filename from the original path\n",
    "            row[1] = os.path.join(constant_path, img_file_name)  # Create the new path with the constant path and filename\n",
    "\n",
    "    # Move the file pointer to the beginning\n",
    "    file.seek(0)\n",
    "\n",
    "    # Write the modified rows back to the CSV file\n",
    "    csv_writer = csv.writer(file)\n",
    "    csv_writer.writerows(rows)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' modified with constant path replacing each file path in the second column.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alex/tflite_model_maker_wsl2\n",
      "convert png image files to jpeg imgs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872c8a5583684775ab5445abe8100414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 0\n",
      "Ignored 17220 files because: Not a PNG file\n",
      "Ignored 1547 files because: Not found\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "%run 'png_to_jpeg.py' {csv_file_path} \n",
    "#%run 'png_to_jpeg.py' annotations1650_mlflow_shuffled_n.csv execute this line after training session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing images:  15%|█▍        | 1069/7266 [03:33<15:35,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing e82677308afcf9cb_IMG_20230622_114747.jpg: cannot identify image file '/home/alex/allImgs_extracted/e82677308afcf9cb_IMG_20230622_114747.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing images:  45%|████▍     | 3251/7266 [10:55<10:08,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 2ea95cbde7c6aca9_IMG_20230622_115029.jpg: cannot identify image file '/home/alex/allImgs_extracted/2ea95cbde7c6aca9_IMG_20230622_115029.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing images: 100%|██████████| 7266/7266 [24:53<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 images did not need resizing. Copied to /home/alex/allImgs_extracted_smaller/4059e4cdc4670770_20231012_131640.jpg\n",
      "7257 did need resizing. Copied to /home/alex/allImgs_extracted_smaller/4059e4cdc4670770_20231012_131640.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# make images smaller (run only when new images have been loaded)\n",
    "\n",
    "%run preproc_imgs.py /home/alex/allImgs_extracted /home/alex/allImgs_extracted_smaller 800\n",
    "#%run preproc_imgs.py /mnt/z/annotated_individual/images/ /home/alex/individual_tiny_extracted_smaller 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir, file_name = os.path.split(csv_file_path)\n",
    "file_base, ext = os.path.splitext(file_name)\n",
    "\n",
    "normalized_csv = os.path.join(dir, f\"{file_base}_n{ext}\")\n",
    "\n",
    "%run normalize_csv.py {csv_file_path}  {normalized_csv} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the stats of the dataset splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2709 different files in this set\n",
      "There are 25 different classes in this set\n",
      "Classes: Onion, Lemon, Ginger, Orange, Eggplant, Scallion, Cucumber, Lime, Banana, Tomato, Apple, Carrot, other, Zucchini, Broccoli, Avocado, Bell-Pepper, Chilli, Egg, Pumpkin, Cabagge, Garlic, Potato, Mango, Cauliflower\n",
      "Onion occurs in 827 different files\n",
      "Lemon occurs in 554 different files\n",
      "Ginger occurs in 447 different files\n",
      "Orange occurs in 286 different files\n",
      "Eggplant occurs in 182 different files\n",
      "Scallion occurs in 564 different files\n",
      "Cucumber occurs in 688 different files\n",
      "Lime occurs in 326 different files\n",
      "Banana occurs in 579 different files\n",
      "Tomato occurs in 798 different files\n",
      "Apple occurs in 396 different files\n",
      "Carrot occurs in 555 different files\n",
      "other occurs in 1412 different files\n",
      "Zucchini occurs in 481 different files\n",
      "Broccoli occurs in 122 different files\n",
      "Avocado occurs in 301 different files\n",
      "Bell-Pepper occurs in 650 different files\n",
      "Chilli occurs in 247 different files\n",
      "Egg occurs in 337 different files\n",
      "Pumpkin occurs in 201 different files\n",
      "Cabagge occurs in 252 different files\n",
      "Garlic occurs in 488 different files\n",
      "Potato occurs in 408 different files\n",
      "Mango occurs in 82 different files\n",
      "Cauliflower occurs in 27 different files\n",
      "\n",
      "Class Distribution in Splits:\n",
      "\n",
      "TRAIN:\n",
      "Onion: 658 files (7.31%)\n",
      "Lemon: 461 files (5.12%)\n",
      "Ginger: 367 files (4.08%)\n",
      "Orange: 234 files (2.6%)\n",
      "Eggplant: 145 files (1.61%)\n",
      "Scallion: 451 files (5.01%)\n",
      "Cucumber: 547 files (6.08%)\n",
      "Lime: 261 files (2.9%)\n",
      "Banana: 481 files (5.34%)\n",
      "Tomato: 636 files (7.07%)\n",
      "Apple: 331 files (3.68%)\n",
      "Carrot: 440 files (4.89%)\n",
      "other: 1131 files (12.56%)\n",
      "Zucchini: 389 files (4.32%)\n",
      "Broccoli: 96 files (1.07%)\n",
      "Avocado: 239 files (2.65%)\n",
      "Bell-Pepper: 503 files (5.59%)\n",
      "Chilli: 204 files (2.27%)\n",
      "Egg: 260 files (2.89%)\n",
      "Pumpkin: 167 files (1.86%)\n",
      "Cabagge: 193 files (2.14%)\n",
      "Garlic: 407 files (4.52%)\n",
      "Potato: 310 files (3.44%)\n",
      "Mango: 70 files (0.78%)\n",
      "Cauliflower: 21 files (0.23%)\n",
      "\n",
      "TEST:\n",
      "other: 152 files (14.3%)\n",
      "Bell-Pepper: 74 files (6.96%)\n",
      "Lime: 33 files (3.1%)\n",
      "Eggplant: 22 files (2.07%)\n",
      "Cabagge: 25 files (2.35%)\n",
      "Banana: 44 files (4.14%)\n",
      "Zucchini: 40 files (3.76%)\n",
      "Tomato: 80 files (7.53%)\n",
      "Avocado: 28 files (2.63%)\n",
      "Onion: 78 files (7.34%)\n",
      "Ginger: 38 files (3.57%)\n",
      "Chilli: 25 files (2.35%)\n",
      "Pumpkin: 11 files (1.03%)\n",
      "Orange: 20 files (1.88%)\n",
      "Garlic: 38 files (3.57%)\n",
      "Apple: 32 files (3.01%)\n",
      "Cauliflower: 3 files (0.28%)\n",
      "Broccoli: 14 files (1.32%)\n",
      "Scallion: 46 files (4.33%)\n",
      "Carrot: 54 files (5.08%)\n",
      "Cucumber: 69 files (6.49%)\n",
      "Egg: 40 files (3.76%)\n",
      "Potato: 46 files (4.33%)\n",
      "Lemon: 44 files (4.14%)\n",
      "Mango: 7 files (0.66%)\n",
      "\n",
      "VALIDATE:\n",
      "Lime: 32 files (2.79%)\n",
      "Garlic: 43 files (3.76%)\n",
      "Ginger: 42 files (3.67%)\n",
      "Tomato: 82 files (7.16%)\n",
      "other: 129 files (11.27%)\n",
      "Scallion: 67 files (5.85%)\n",
      "Avocado: 34 files (2.97%)\n",
      "Bell-Pepper: 73 files (6.38%)\n",
      "Cucumber: 72 files (6.29%)\n",
      "Cabagge: 34 files (2.97%)\n",
      "Onion: 91 files (7.95%)\n",
      "Carrot: 61 files (5.33%)\n",
      "Apple: 33 files (2.88%)\n",
      "Eggplant: 15 files (1.31%)\n",
      "Orange: 32 files (2.79%)\n",
      "Lemon: 49 files (4.28%)\n",
      "Zucchini: 52 files (4.54%)\n",
      "Egg: 37 files (3.23%)\n",
      "Banana: 54 files (4.72%)\n",
      "Chilli: 18 files (1.57%)\n",
      "Potato: 52 files (4.54%)\n",
      "Broccoli: 12 files (1.05%)\n",
      "Pumpkin: 23 files (2.01%)\n",
      "Mango: 5 files (0.44%)\n",
      "Cauliflower: 3 files (0.26%)\n"
     ]
    }
   ],
   "source": [
    "#annotations_base_filename = \"annotations1900\"\n",
    "%run 'get_label_stats.py' {normalized_csv} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea9eed0",
   "metadata": {},
   "source": [
    "### Optionally remove other class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c38e6e1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines containing 'other' removed. Output written to 'annotations/annotations_2709_mlflow_shuffled_n_no_other.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def remove_lines_with_infix(input_filename, infix_to_remove):\n",
    "    directory, file_name = os.path.split(input_filename)\n",
    "    file_base, file_extension = os.path.splitext(file_name)\n",
    "    output_filename = os.path.join(directory, file_base + \"_no_\" + infix_to_remove + file_extension)\n",
    "\n",
    "    with open(input_filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Remove lines containing the infix\n",
    "    filtered_lines = [line for line in lines if infix_to_remove not in line]\n",
    "\n",
    "    with open(output_filename, 'w') as file:\n",
    "        file.writelines(filtered_lines)\n",
    "\n",
    "    print(f\"Lines containing '{infix_to_remove}' removed. Output written to '{output_filename}'.\")\n",
    "\n",
    "# Example usage\n",
    "# remove_lines_with_infix('/path/to/your/file.txt', 'infix_to_remove')\n",
    "\n",
    "\n",
    "remove_lines_with_infix(normalized_csv,\"other\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can start to load the model and train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba09f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "# The current code uses Focal loss which has already weighted loss because of alpha and gamma\n",
    "model_name = 'efficientdet-lite0' # EfficientDetLite1Spec must also be set accordingly!\n",
    "custom_model_dir_name = 'model_'+\"2709_test\"#str(num_distinct_files)\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "model_dir = 'models/'+model_name+'/'+custom_model_dir_name+'_e'+str(epochs)+'_b'+str(batch_size)\n",
    "#spec = model_spec.get('efficientdet_lite1')\n",
    "# check this url to check valid hparam values\n",
    "# https://github.com/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/third_party/efficientdet/hparams_config.py\n",
    "spec = object_detector.EfficientDetLite0Spec( # change this also to correct model spec\n",
    "    model_name = model_name,\n",
    "    model_dir='/home/alex/checkpoints/',\n",
    "    hparams='grad_checkpoint=true,strategy=gpus',\n",
    "    epochs=epochs, batch_size=batch_size,\n",
    "    steps_per_execution=1, moving_average_decay=0,\n",
    "    var_freeze_expr='(efficientnet|fpn_cells|resample_p6)',\n",
    "    tflite_max_detections=25\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26b4f5",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get an error here run the png to jpeg script again. Inference seems to fuck it up ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ad66896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/alex/tflite_model_maker_wsl2\n",
      "The file 'annotations/annotations_2709_mlflow_shuffled_n.csv' exists.\n"
     ]
    }
   ],
   "source": [
    "#annotations_base_filename = 'annotations1900'\n",
    "# png to jpeg needs to run again after inference\n",
    "# %run 'png_to_jpeg.py' {normalized_csv} \n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_directory)\n",
    "\n",
    "# file_path = '/home/alex/tflite_model_maker_wsl2/'+annotations_base_filename +\"_mlflow_shuffled_n.csv\"\n",
    "file_path = normalized_csv\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"The file '{file_path}' exists.\")\n",
    "train_data, validation_data, test_data = object_detector.DataLoader.from_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ce5fa6",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ca0f89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 12:49:55.991401: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 151s 486ms/step - det_loss: 1.6713 - cls_loss: 1.0918 - box_loss: 0.0116 - reg_l2_loss: 0.0671 - loss: 1.7384 - learning_rate: 0.0090 - gradient_norm: 0.9606 - val_det_loss: 1.5957 - val_cls_loss: 1.0479 - val_box_loss: 0.0110 - val_reg_l2_loss: 0.0671 - val_loss: 1.6627\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 125s 465ms/step - det_loss: 1.4725 - cls_loss: 0.9688 - box_loss: 0.0101 - reg_l2_loss: 0.0670 - loss: 1.5396 - learning_rate: 0.0100 - gradient_norm: 1.3262 - val_det_loss: 1.5093 - val_cls_loss: 0.9836 - val_box_loss: 0.0105 - val_reg_l2_loss: 0.0670 - val_loss: 1.5764\n",
      "Epoch 3/50\n",
      " 97/270 [=========>....................] - ETA: 1:27 - det_loss: 1.4225 - cls_loss: 0.9336 - box_loss: 0.0098 - reg_l2_loss: 0.0670 - loss: 1.4895 - learning_rate: 0.0100 - gradient_norm: 1.4896"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mobject_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_whole_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/examples/tensorflow_examples/lite/model_maker/pip_package/src/tensorflow_examples/lite/model_maker/core/task/object_detector.py:260\u001b[0m, in \u001b[0;36mObjectDetector.create\u001b[0;34m(cls, train_data, model_spec, validation_data, epochs, batch_size, train_whole_model, do_train)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_train:\n\u001b[1;32m    259\u001b[0m   tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetraining the models...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 260\u001b[0m   \u001b[43mobject_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m   object_detector\u001b[38;5;241m.\u001b[39mcreate_model()\n",
      "File \u001b[0;32m~/examples/tensorflow_examples/lite/model_maker/pip_package/src/tensorflow_examples/lite/model_maker/core/task/object_detector.py:123\u001b[0m, in \u001b[0;36mObjectDetector.train\u001b[0;34m(self, train_data, validation_data, epochs, batch_size)\u001b[0m\n\u001b[1;32m    119\u001b[0m train_ds, steps_per_epoch, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_and_steps(\n\u001b[1;32m    120\u001b[0m     train_data, batch_size, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    121\u001b[0m validation_ds, validation_steps, val_json_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_and_steps(\n\u001b[1;32m    122\u001b[0m     validation_data, batch_size, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mvalidation_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_json_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/examples/tensorflow_examples/lite/model_maker/pip_package/src/tensorflow_examples/lite/model_maker/core/task/model_spec/object_detector_spec.py:265\u001b[0m, in \u001b[0;36mEfficientDetModelSpec.train\u001b[0;34m(self, model, train_dataset, steps_per_epoch, val_dataset, validation_steps, epochs, batch_size, val_json_file)\u001b[0m\n\u001b[1;32m    263\u001b[0m train\u001b[38;5;241m.\u001b[39msetup_model(model, config)\n\u001b[1;32m    264\u001b[0m train\u001b[38;5;241m.\u001b[39minit_experimental(config)\n\u001b[0;32m--> 265\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = object_detector.create(train_data, model_spec=spec, train_whole_model=True, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the model maker class list to a file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out this instead maybe dl new version first (did not work with old one) model.export_labels(model_dir+'/label_map.json')\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "label_map = model.model_spec.config.label_map.as_dict()\n",
    "# Writing the dictionary to a JSON file\n",
    "with open(model_dir+'/label_map.json', 'w') as file:\n",
    "    json.dump(label_map, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run tensorboard to monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=/home/alex/checkpoints_lite1_1700imgs/ --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4952ee",
   "metadata": {},
   "source": [
    "Run on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18520724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 8s 141ms/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AP': 0.08548653,\n",
       " 'AP50': 0.1361972,\n",
       " 'AP75': 0.09609742,\n",
       " 'APs': 0.0,\n",
       " 'APm': 0.055434335,\n",
       " 'APl': 0.10378562,\n",
       " 'ARmax1': 0.09282439,\n",
       " 'ARmax10': 0.16570528,\n",
       " 'ARmax100': 0.17741416,\n",
       " 'ARs': 0.0,\n",
       " 'ARm': 0.11349891,\n",
       " 'ARl': 0.20717403,\n",
       " 'AP_/other': 0.2532248,\n",
       " 'AP_/Potato': 0.12074429,\n",
       " 'AP_/Tomato': 0.15464021,\n",
       " 'AP_/Onion': 0.12620524,\n",
       " 'AP_/Apple': 0.09803807,\n",
       " 'AP_/Banana': 0.2172316,\n",
       " 'AP_/Pumpkin': 0.0325109,\n",
       " 'AP_/Scallion': 0.061618336,\n",
       " 'AP_/Avocado': 0.09182611,\n",
       " 'AP_/Lemon': 0.08666255,\n",
       " 'AP_/Bell-Pepper': 0.14741343,\n",
       " 'AP_/Carrot': 0.049910072,\n",
       " 'AP_/Egg': 0.13089462,\n",
       " 'AP_/Cucumber': 0.07713252,\n",
       " 'AP_/Zucchini': 0.044840463,\n",
       " 'AP_/Chilli': 0.0001142422,\n",
       " 'AP_/Lime': 0.03753449,\n",
       " 'AP_/Ginger': 0.08042903,\n",
       " 'AP_/Garlic': 0.041250616,\n",
       " 'AP_/Cabagge': 0.07485298,\n",
       " 'AP_/Mango': 0.0,\n",
       " 'AP_/Eggplant': 0.027572501,\n",
       " 'AP_/Broccoli': 0.0970297,\n",
       " 'AP_/Cauliflower': 0.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ae545d",
   "metadata": {},
   "source": [
    "### Export the model to tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a168367b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 22:55:52.942000: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2024-01-07 22:56:07.102552: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 3 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 1.834 G  ops, equivalently 0.917 G  MACs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 22:56:11.098355: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2024-01-07 22:56:11.098387: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2024-01-07 22:56:11.101489: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpe1doj34a\n",
      "2024-01-07 22:56:11.160670: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2024-01-07 22:56:11.160691: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmpe1doj34a\n",
      "2024-01-07 22:56:11.366282: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2024-01-07 22:56:12.367672: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpe1doj34a\n",
      "2024-01-07 22:56:12.809680: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1708856 microseconds.\n",
      "2024-01-07 22:56:13.708576: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-07 22:56:14.628536: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.834 G  ops, equivalently 0.917 G  MACs\n",
      "\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 0\n",
      "2024-01-07 22:57:25.591020: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.834 G  ops, equivalently 0.917 G  MACs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 1.834 G  ops, equivalently 0.917 G  MACs\n",
      "exported to model to models/efficientdet-lite0/model_2488_more_classes_e50_b8\n"
     ]
    }
   ],
   "source": [
    "model.export(export_dir=model_dir)\n",
    "print(f\"exported to model to {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on TFLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 254s 1s/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AP': 0.072127916,\n",
       " 'AP50': 0.112064324,\n",
       " 'AP75': 0.07951266,\n",
       " 'APs': 0.0,\n",
       " 'APm': 0.034183107,\n",
       " 'APl': 0.08941372,\n",
       " 'ARmax1': 0.06421327,\n",
       " 'ARmax10': 0.10355284,\n",
       " 'ARmax100': 0.105854,\n",
       " 'ARs': 0.0,\n",
       " 'ARm': 0.054981574,\n",
       " 'ARl': 0.12072811,\n",
       " 'AP_/Cabagge': 0.058613863,\n",
       " 'AP_/Cauliflower': 0.0,\n",
       " 'AP_/Lime': 0.025742574,\n",
       " 'AP_/other': 0.22228026,\n",
       " 'AP_/Chilli': 0.000990099,\n",
       " 'AP_/Tomato': 0.065596685,\n",
       " 'AP_/Cucumber': 0.01336198,\n",
       " 'AP_/Mango': 0.0,\n",
       " 'AP_/Lemon': 0.059609786,\n",
       " 'AP_/Bell-Pepper': 0.10160959,\n",
       " 'AP_/Carrot': 0.022990871,\n",
       " 'AP_/Onion': 0.12955928,\n",
       " 'AP_/Zucchini': 0.0016142919,\n",
       " 'AP_/Ginger': 0.15429042,\n",
       " 'AP_/Garlic': 0.062772274,\n",
       " 'AP_/Potato': 0.19233683,\n",
       " 'AP_/Scallion': 0.0071628676,\n",
       " 'AP_/Avocado': 0.0,\n",
       " 'AP_/Broccoli': 0.054455444,\n",
       " 'AP_/Pumpkin': 0.14257425,\n",
       " 'AP_/Banana': 0.15792875,\n",
       " 'AP_/Eggplant': 0.0,\n",
       " 'AP_/Egg': 0.20838435,\n",
       " 'AP_/Apple': 0.049195543}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "#model_dir='models/efficientdet-lite0/model_1907_e50_b16/model.tflite'\n",
    "model.evaluate_tflite(model_dir+'/model.tflite', test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d704b3",
   "metadata": {},
   "source": [
    "Run inference script for visual output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0344fa93",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert png image files to jpeg imgs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513fd623808d44a7a7132b50a02212a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 0\n",
      "Ignored 16196 files because: Not a PNG file\n",
      "Ignored 0 files because: Not found\n",
      "Predications will be saved to output_inference12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [04:34<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# needs to be after training for some reason\n",
    "\n",
    "%run 'png_to_jpeg.py' {annotations_base_filename +\"_mlflow_shuffled_n.csv\"}\n",
    "\n",
    "\n",
    "%run do_inference.py --input_csv {annotations_base_filename +\"_mlflow_shuffled_n.csv\"}\\\n",
    "                       --model_url {model_dir}/model.tflite --output_dir output_inference12 --label_file {model_dir}/label_map.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
