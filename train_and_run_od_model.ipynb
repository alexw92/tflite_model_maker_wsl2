{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163f06e7",
   "metadata": {},
   "source": [
    "# Load the pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archive Images (on Server!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "tar -czf /home/alex/all_imgs_07_01_24.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b844c8",
   "metadata": {},
   "source": [
    "#### Better: Just download the delta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c52b6c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "scp aug_4904_cv_fold_0.csv alex@foodsnapai.com:/home/alex/data.csv\n",
    "\n",
    "# On the server\n",
    "python archive_new_files.py --csv_file data.csv --in_dir label-studio-dir/media/upload/4 --out_dir /home/alex/deltaImgs\n",
    "# this will generate delta_imgs.tar.gz ready to be downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download archive from server and extract it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_imgs.tar.gz                             100%  140MB  95.4MB/s   00:01    \n"
     ]
    }
   ],
   "source": [
    "!scp alex@foodsnapai.com:/home/alex/delta_imgs.tar.gz /home/alex/delta_imgs.tar.gz\n",
    "!tar -xzf /home/alex/delta_imgs.tar.gz -C /home/alex/allImgs_extracted/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load annotations without Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations/annotations_single.csv\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1302k  100 1302k    0     0  86718      0  0:00:15  0:00:15 --:--:--  313k\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the value of the environment variable\n",
    "labelstudio_token = os.getenv('LABELSTUDIO_TOKEN')\n",
    "annotations_dir = \"annotations/\"\n",
    "filename = \"annotations_single\"\n",
    "file_path = os.path.join(annotations_dir, filename + \".csv\")\n",
    "project_id_single_groceries=4\n",
    "project_id_mixed_groceries=1\n",
    "!echo {file_path} \n",
    "!curl http://foodsnapai.com:8080/api/projects/4/export?exportType=CSV -H 'Authorization: Token {labelstudio_token}' --output {file_path} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert annotations and images and preprocess them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming original image dir is /home/alex/allImgs_extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2998/2998 [00:02<00:00, 1210.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Rotations from 3: 36\n",
      "#Rotations from 6: 3154\n",
      "Rotations from 8: 10\n",
      "Distinct files in dataset: 2998\n",
      "File renamed to: annotations/annotations_single_2998_mlflow.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "%run 'convert_csv_to_mlflow_csv.py' {file_path} \n",
    "\n",
    "mlflow_filename = os.path.join(annotations_dir, filename + \"_mlflow.csv\") \n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(mlflow_filename)\n",
    "\n",
    "# Count distinct values in the 'path' column\n",
    "distinct_files = df['path'].unique()\n",
    "num_distinct_files = len(distinct_files)\n",
    "\n",
    "# Rename the file to include the number of images\n",
    "base_name, extension = os.path.splitext(filename)\n",
    "new_filename =os.path.join(annotations_dir, f\"{filename}_{num_distinct_files}_mlflow.csv\") \n",
    "os.rename(mlflow_filename, new_filename)\n",
    "\n",
    "print(f\"Distinct files in dataset: {num_distinct_files}\")\n",
    "print(f\"File renamed to: {new_filename}\")\n",
    "annotations_full_filename = new_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping automatic class merge.\n",
      "['Tomato', 'Cucumber', 'Bell-Pepper', 'Onion', 'Carrot', 'Banana', 'Egg', 'Scallion', 'Lemon', 'Potato', 'Zucchini', 'Garlic', 'Apple', 'Pumpkin', 'Ginger', 'Lime', 'Avocado', 'Mango', 'Broccoli', 'Chilli', 'Cauliflower', 'Eggplant', 'Cabagge', 'Orange']\n",
      "Merging classes ['Mushroom', 'Corn', 'Salad'] to 'other'\n",
      "Train-test-validation split applied to annotations/annotations_single_2998_mlflow_shuffled.csv\n"
     ]
    }
   ],
   "source": [
    "# merge classes here\n",
    "# curret merge string: not:Tomato,Cucumber,Bell-Pepper,Onion,Carrot,Banana,Egg,Scallion,Lemon,Potato,Zucchini,Garlic,Apple,Pumpkin,Ginger\n",
    "# not:Tomato,Cucumber,Bell-Pepper,Onion,Carrot,Banana,Egg,Scallion,Lemon,Potato,Zucchini,Garlic,Apple,Pumpkin,Ginger,Lime,Avocado,Mango,Broccoli,Chilli,Cauliflower,Eggplant,Cabagge,Orange\n",
    "# annotations_full_filename = \"annotations_single\"    +\"_mlflow.csv\"\n",
    "%run 'convert_pascal_to_googlecsv.py' --merged_csv {annotations_full_filename} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now rename the file paths in the file to their actual location (find & replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'annotations/annotations_single_2998_mlflow_shuffled.csv' modified with constant path replacing each file path in the second column.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Constant path to prepend\n",
    "constant_path = '/home/alex/allImgs_extracted_smaller/'\n",
    "\n",
    "# CSV file path\n",
    "csv_dir, csv_filename = os.path.split(annotations_full_filename)\n",
    "csv_base, csv_ext = os.path.splitext(csv_filename)\n",
    "# add shuffled suffix because convert_pascal_to_googlecsv.py appends this\n",
    "csv_file_path = os.path.join(csv_dir, f\"{csv_base}_shuffled{csv_ext}\")\n",
    "\n",
    "# Open the CSV file and modify the paths in the second column\n",
    "with open(csv_file_path, 'r+', newline='') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    rows = list(csv_reader)\n",
    "\n",
    "    for row in rows:\n",
    "        if len(row) > 1:  # Ensure the row has at least two columns\n",
    "            # Assuming the file path is in the second column (index 1)\n",
    "            img_file_path = row[1]\n",
    "            img_file_name = os.path.basename(img_file_path)  # Extract the filename from the original path\n",
    "            row[1] = os.path.join(constant_path, img_file_name)  # Create the new path with the constant path and filename\n",
    "\n",
    "    # Move the file pointer to the beginning\n",
    "    file.seek(0)\n",
    "\n",
    "    # Write the modified rows back to the CSV file\n",
    "    csv_writer = csv.writer(file)\n",
    "    csv_writer.writerows(rows)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' modified with constant path replacing each file path in the second column.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc17003a",
   "metadata": {},
   "source": [
    "This code usually does not need to run since Mobile Phones dont upload pngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alex/tflite_model_maker_wsl2\n",
      "convert png image files to jpeg imgs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872c8a5583684775ab5445abe8100414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 0\n",
      "Ignored 17220 files because: Not a PNG file\n",
      "Ignored 1547 files because: Not found\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "%run 'png_to_jpeg.py' {csv_file_path} \n",
    "#%run 'png_to_jpeg.py' annotations1650_mlflow_shuffled_n.csv execute this line after training session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing images:  15%|█▌        | 1216/8070 [00:03<00:22, 308.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing e82677308afcf9cb_IMG_20230622_114747.jpg: cannot identify image file '/home/alex/allImgs_extracted/e82677308afcf9cb_IMG_20230622_114747.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing images:  45%|████▌     | 3667/8070 [00:10<00:09, 478.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 2ea95cbde7c6aca9_IMG_20230622_115029.jpg: cannot identify image file '/home/alex/allImgs_extracted/2ea95cbde7c6aca9_IMG_20230622_115029.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing images: 100%|██████████| 8070/8070 [00:23<00:00, 341.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7265 images did not need resizing. Copied to /home/alex/allImgs_extracted_smaller/4059e4cdc4670770_20231012_131640.jpg\n",
      "803 did need resizing. Copied to /home/alex/allImgs_extracted_smaller/4059e4cdc4670770_20231012_131640.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# make images smaller (run only when new images have been loaded)\n",
    "\n",
    "%run preproc_imgs.py /home/alex/allImgs_extracted /home/alex/allImgs_extracted_smaller 800\n",
    "#%run preproc_imgs.py /mnt/z/annotated_individual/images/ /home/alex/individual_tiny_extracted_smaller 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir, file_name = os.path.split(csv_file_path)\n",
    "file_base, ext = os.path.splitext(file_name)\n",
    "\n",
    "normalized_csv = os.path.join(dir, f\"{file_base}_n{ext}\")\n",
    "\n",
    "%run normalize_csv.py {csv_file_path}  {normalized_csv} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the stats of the dataset splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5707 different files in this set\n",
      "There are 25 different classes in this set\n",
      "Classes: Orange, Lemon, Ginger, Cabagge, Lime, Onion, Zucchini, Chilli, Carrot, Egg, other, Bell-Pepper, Pumpkin, Broccoli, Garlic, Cucumber, Scallion, Potato, Apple, Tomato, Eggplant, Banana, Avocado, Mango, Cauliflower\n",
      "Orange occurs in 419 different files\n",
      "Lemon occurs in 681 different files\n",
      "Ginger occurs in 562 different files\n",
      "Cabagge occurs in 407 different files\n",
      "Lime occurs in 443 different files\n",
      "Onion occurs in 1034 different files\n",
      "Zucchini occurs in 632 different files\n",
      "Chilli occurs in 479 different files\n",
      "Carrot occurs in 621 different files\n",
      "Egg occurs in 357 different files\n",
      "other occurs in 1431 different files\n",
      "Bell-Pepper occurs in 1018 different files\n",
      "Pumpkin occurs in 331 different files\n",
      "Broccoli occurs in 188 different files\n",
      "Garlic occurs in 659 different files\n",
      "Cucumber occurs in 849 different files\n",
      "Scallion occurs in 638 different files\n",
      "Potato occurs in 550 different files\n",
      "Apple occurs in 445 different files\n",
      "Tomato occurs in 922 different files\n",
      "Eggplant occurs in 242 different files\n",
      "Banana occurs in 676 different files\n",
      "Avocado occurs in 370 different files\n",
      "Mango occurs in 153 different files\n",
      "Cauliflower occurs in 107 different files\n",
      "\n",
      "Class Distribution in Splits:\n",
      "\n",
      "TRAIN:\n",
      "Orange: 336 files (2.94%)\n",
      "Lemon: 552 files (4.83%)\n",
      "Ginger: 461 files (4.04%)\n",
      "Cabagge: 326 files (2.85%)\n",
      "Lime: 376 files (3.29%)\n",
      "Onion: 822 files (7.2%)\n",
      "Zucchini: 497 files (4.35%)\n",
      "Chilli: 394 files (3.45%)\n",
      "Carrot: 508 files (4.45%)\n",
      "Egg: 278 files (2.43%)\n",
      "other: 1146 files (10.04%)\n",
      "Bell-Pepper: 816 files (7.15%)\n",
      "Pumpkin: 262 files (2.29%)\n",
      "Broccoli: 151 files (1.32%)\n",
      "Garlic: 532 files (4.66%)\n",
      "Cucumber: 674 files (5.9%)\n",
      "Scallion: 503 files (4.4%)\n",
      "Potato: 446 files (3.91%)\n",
      "Apple: 358 files (3.13%)\n",
      "Tomato: 734 files (6.43%)\n",
      "Eggplant: 181 files (1.58%)\n",
      "Banana: 552 files (4.83%)\n",
      "Avocado: 298 files (2.61%)\n",
      "Mango: 135 files (1.18%)\n",
      "Cauliflower: 82 files (0.72%)\n",
      "\n",
      "TEST:\n",
      "Orange: 49 files (3.46%)\n",
      "Banana: 65 files (4.59%)\n",
      "Ginger: 54 files (3.82%)\n",
      "Lime: 34 files (2.4%)\n",
      "Lemon: 55 files (3.89%)\n",
      "Tomato: 108 files (7.63%)\n",
      "other: 144 files (10.18%)\n",
      "Bell-Pepper: 94 files (6.64%)\n",
      "Cucumber: 98 files (6.93%)\n",
      "Onion: 106 files (7.49%)\n",
      "Potato: 52 files (3.67%)\n",
      "Carrot: 58 files (4.1%)\n",
      "Chilli: 47 files (3.32%)\n",
      "Garlic: 58 files (4.1%)\n",
      "Scallion: 78 files (5.51%)\n",
      "Apple: 45 files (3.18%)\n",
      "Eggplant: 30 files (2.12%)\n",
      "Cabagge: 33 files (2.33%)\n",
      "Zucchini: 66 files (4.66%)\n",
      "Avocado: 35 files (2.47%)\n",
      "Egg: 40 files (2.83%)\n",
      "Pumpkin: 32 files (2.26%)\n",
      "Mango: 10 files (0.71%)\n",
      "Broccoli: 16 files (1.13%)\n",
      "Cauliflower: 8 files (0.57%)\n",
      "\n",
      "VALIDATE:\n",
      "Banana: 59 files (4.28%)\n",
      "Tomato: 80 files (5.8%)\n",
      "other: 141 files (10.22%)\n",
      "Zucchini: 69 files (5.0%)\n",
      "Cucumber: 77 files (5.58%)\n",
      "Potato: 52 files (3.77%)\n",
      "Chilli: 38 files (2.76%)\n",
      "Onion: 106 files (7.69%)\n",
      "Ginger: 47 files (3.41%)\n",
      "Garlic: 69 files (5.0%)\n",
      "Egg: 39 files (2.83%)\n",
      "Avocado: 37 files (2.68%)\n",
      "Lemon: 74 files (5.37%)\n",
      "Scallion: 57 files (4.13%)\n",
      "Cabagge: 48 files (3.48%)\n",
      "Bell-Pepper: 108 files (7.83%)\n",
      "Broccoli: 21 files (1.52%)\n",
      "Carrot: 55 files (3.99%)\n",
      "Orange: 34 files (2.47%)\n",
      "Pumpkin: 37 files (2.68%)\n",
      "Eggplant: 31 files (2.25%)\n",
      "Lime: 33 files (2.39%)\n",
      "Apple: 42 files (3.05%)\n",
      "Cauliflower: 17 files (1.23%)\n",
      "Mango: 8 files (0.58%)\n"
     ]
    }
   ],
   "source": [
    "#annotations_base_filename = \"annotations1900\"\n",
    "normalized_csv = './annotations/annotations_combined_5705.csv '\n",
    "%run 'get_label_stats.py' {normalized_csv} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a0bc4c",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "You can also create cross validation folds.\n",
    "This script will create balanced folds and return 5 runable Datasets with distinct eval folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b6e73c1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Number of unique images: 1142\n",
      "Number of images: 4508\n",
      "Label Distribution:\n",
      "other          729\n",
      "Tomato         395\n",
      "Onion          317\n",
      "Bell-Pepper    302\n",
      "Potato         248\n",
      "Garlic         232\n",
      "Egg            198\n",
      "Cucumber       194\n",
      "Lemon          174\n",
      "Carrot         173\n",
      "Chilli         168\n",
      "Apple          157\n",
      "Zucchini       152\n",
      "Scallion       144\n",
      "Ginger         133\n",
      "Orange         131\n",
      "Banana         128\n",
      "Lime           126\n",
      "Avocado         91\n",
      "Cabagge         85\n",
      "Pumpkin         84\n",
      "Broccoli        46\n",
      "Eggplant        42\n",
      "Mango           38\n",
      "Cauliflower     21\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "Fold 1:\n",
      "Number of unique images: 1142\n",
      "Number of images: 4594\n",
      "Label Distribution:\n",
      "other          802\n",
      "Tomato         414\n",
      "Onion          320\n",
      "Bell-Pepper    301\n",
      "Garlic         257\n",
      "Potato         240\n",
      "Lemon          195\n",
      "Egg            189\n",
      "Carrot         186\n",
      "Cucumber       178\n",
      "Apple          168\n",
      "Zucchini       158\n",
      "Chilli         141\n",
      "Ginger         139\n",
      "Banana         135\n",
      "Lime           131\n",
      "Orange         130\n",
      "Scallion       129\n",
      "Cabagge         77\n",
      "Avocado         73\n",
      "Pumpkin         66\n",
      "Eggplant        62\n",
      "Broccoli        44\n",
      "Mango           36\n",
      "Cauliflower     23\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "Fold 2:\n",
      "Number of unique images: 1141\n",
      "Number of images: 4727\n",
      "Label Distribution:\n",
      "other          722\n",
      "Tomato         420\n",
      "Bell-Pepper    389\n",
      "Onion          356\n",
      "Garlic         250\n",
      "Potato         248\n",
      "Lemon          202\n",
      "Cucumber       196\n",
      "Carrot         175\n",
      "Egg            171\n",
      "Zucchini       167\n",
      "Apple          154\n",
      "Lime           147\n",
      "Scallion       143\n",
      "Chilli         142\n",
      "Orange         141\n",
      "Banana         134\n",
      "Ginger         130\n",
      "Avocado        104\n",
      "Cabagge         92\n",
      "Pumpkin         81\n",
      "Eggplant        68\n",
      "Broccoli        46\n",
      "Mango           27\n",
      "Cauliflower     22\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "Fold 3:\n",
      "Number of unique images: 1141\n",
      "Number of images: 4746\n",
      "Label Distribution:\n",
      "other          691\n",
      "Tomato         461\n",
      "Onion          351\n",
      "Bell-Pepper    330\n",
      "Potato         238\n",
      "Garlic         234\n",
      "Lemon          233\n",
      "Cucumber       208\n",
      "Carrot         206\n",
      "Egg            203\n",
      "Zucchini       176\n",
      "Banana         159\n",
      "Apple          158\n",
      "Lime           155\n",
      "Chilli         147\n",
      "Scallion       130\n",
      "Ginger         121\n",
      "Orange         120\n",
      "Avocado        109\n",
      "Pumpkin         85\n",
      "Cabagge         78\n",
      "Eggplant        61\n",
      "Broccoli        38\n",
      "Mango           31\n",
      "Cauliflower     23\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "Fold 4:\n",
      "Number of unique images: 1141\n",
      "Number of images: 4544\n",
      "Label Distribution:\n",
      "other          759\n",
      "Tomato         416\n",
      "Bell-Pepper    317\n",
      "Onion          290\n",
      "Garlic         237\n",
      "Potato         235\n",
      "Lemon          218\n",
      "Egg            207\n",
      "Cucumber       188\n",
      "Carrot         178\n",
      "Zucchini       169\n",
      "Banana         150\n",
      "Apple          144\n",
      "Scallion       143\n",
      "Chilli         139\n",
      "Lime           126\n",
      "Orange         120\n",
      "Ginger         112\n",
      "Avocado         94\n",
      "Cabagge         92\n",
      "Pumpkin         76\n",
      "Eggplant        58\n",
      "Mango           30\n",
      "Broccoli        27\n",
      "Cauliflower     19\n",
      "Name: Label, dtype: int64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/tflite_model_maker_wsl2/cross_validation_fold_creator.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_data['Split'] = 'VALIDATE'\n",
      "/home/alex/tflite_model_maker_wsl2/cross_validation_fold_creator.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_data['Split'] = 'VALIDATE'\n",
      "/home/alex/tflite_model_maker_wsl2/cross_validation_fold_creator.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_data['Split'] = 'VALIDATE'\n",
      "/home/alex/tflite_model_maker_wsl2/cross_validation_fold_creator.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_data['Split'] = 'VALIDATE'\n",
      "/home/alex/tflite_model_maker_wsl2/cross_validation_fold_creator.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_data['Split'] = 'VALIDATE'\n"
     ]
    }
   ],
   "source": [
    "%run cross_validation_fold_creator.py ./annotations/annotations_combined_5705.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4b715d",
   "metadata": {},
   "source": [
    "### Augment Train Dataset\n",
    "Augmentation can lead to better generalization if applied only on the train dataset and\n",
    "if conservative augmentations are used.\n",
    "This script creates augmentations for already created cross validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "833f8359",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'cv2' has no attribute '_registerMatType' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/tflite_model_maker_wsl2/img_augmentation.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimgaug\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mia\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimgaug\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m augmenters \u001b[38;5;28;01mas\u001b[39;00m iaa\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/imgaug/__init__.py:7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# this contains some deprecated classes/functions pointing to the new\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# classes/functions, hence always place the other imports below this so that\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# the deprecated stuff gets overwritten as much as possible\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimgaug\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimgaug\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimgaug\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmentables\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01maugmentables\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimgaug\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmentables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/imgaug/imgaug.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterable\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/cv2/__init__.py:181\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra Python code for\u001b[39m\u001b[38;5;124m\"\u001b[39m, submodule, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV loader: DONE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbootstrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/cv2/__init__.py:175\u001b[0m, in \u001b[0;36mbootstrap\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV loader: binary extension... OK\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m submodule \u001b[38;5;129;01min\u001b[39;00m __collect_extra_submodules(DEBUG):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m__load_extra_py_code_for_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcv2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEBUG\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra Python code for\u001b[39m\u001b[38;5;124m\"\u001b[39m, submodule, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV loader: DONE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/cv2/__init__.py:28\u001b[0m, in \u001b[0;36m__load_extra_py_code_for_module\u001b[0;34m(base, name, enable_debug_print)\u001b[0m\n\u001b[1;32m     26\u001b[0m native_module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpop(module_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m     py_module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m enable_debug_print:\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/cv2/mat_wrapper/__init__.py:39\u001b[0m\n\u001b[1;32m     37\u001b[0m Mat\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m     38\u001b[0m cv\u001b[38;5;241m.\u001b[39mMat \u001b[38;5;241m=\u001b[39m Mat\n\u001b[0;32m---> 39\u001b[0m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_registerMatType\u001b[49m(Mat)\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'cv2' has no attribute '_registerMatType' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# this must run in conda env \n",
    "%run img_augmentation.py --cv_prefix 5707"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea9eed0",
   "metadata": {},
   "source": [
    "### Optionally remove other class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c38e6e1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines containing 'other' removed. Output written to 'annotations/cross_val/aug_4904_cv_fold_4_no_other.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def remove_lines_with_infix(input_filename, infix_to_remove):\n",
    "    directory, file_name = os.path.split(input_filename)\n",
    "    file_base, file_extension = os.path.splitext(file_name)\n",
    "    output_filename = os.path.join(directory, file_base + \"_no_\" + infix_to_remove + file_extension)\n",
    "\n",
    "    with open(input_filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Remove lines containing the infix\n",
    "    filtered_lines = [line for line in lines if infix_to_remove not in line]\n",
    "\n",
    "    with open(output_filename, 'w') as file:\n",
    "        file.writelines(filtered_lines)\n",
    "\n",
    "    print(f\"Lines containing '{infix_to_remove}' removed. Output written to '{output_filename}'.\")\n",
    "\n",
    "# Example usage\n",
    "# remove_lines_with_infix('/path/to/your/file.txt', 'infix_to_remove')\n",
    "my_file = 'annotations/cross_val/aug_4904_cv_fold_4.csv'\n",
    "\n",
    "remove_lines_with_infix(my_file,\"other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can start to load the model and train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba09f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "# The current code uses Focal loss which has already weighted loss because of alpha and gamma\n",
    "model_name = 'efficientdet-lite0' # EfficientDetLite1Spec must also be set accordingly!\n",
    "custom_model_dir_name = 'model_'+\"2709_test\"#str(num_distinct_files)\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "model_dir = 'models/'+model_name+'/'+custom_model_dir_name+'_e'+str(epochs)+'_b'+str(batch_size)\n",
    "#spec = model_spec.get('efficientdet_lite1')\n",
    "# check this url to check valid hparam values\n",
    "# https://github.com/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/third_party/efficientdet/hparams_config.py\n",
    "spec = object_detector.EfficientDetLite0Spec( # change this also to correct model spec\n",
    "    model_name = model_name,\n",
    "    model_dir='/home/alex/checkpoints/',\n",
    "    hparams='grad_checkpoint=true,strategy=gpus',\n",
    "    epochs=epochs, batch_size=batch_size,\n",
    "    steps_per_execution=1, moving_average_decay=0,\n",
    "    var_freeze_expr='(efficientnet|fpn_cells|resample_p6)',\n",
    "    tflite_max_detections=25\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26b4f5",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get an error here run the png to jpeg script again. Inference seems to fuck it up ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ad66896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/alex/tflite_model_maker_wsl2\n",
      "The file 'annotations/annotations_2709_mlflow_shuffled_n.csv' exists.\n"
     ]
    }
   ],
   "source": [
    "#annotations_base_filename = 'annotations1900'\n",
    "# png to jpeg needs to run again after inference\n",
    "# %run 'png_to_jpeg.py' {normalized_csv} \n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_directory)\n",
    "\n",
    "# file_path = '/home/alex/tflite_model_maker_wsl2/'+annotations_base_filename +\"_mlflow_shuffled_n.csv\"\n",
    "file_path = normalized_csv\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"The file '{file_path}' exists.\")\n",
    "train_data, validation_data, test_data = object_detector.DataLoader.from_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ce5fa6",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ca0f89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 12:49:55.991401: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 151s 486ms/step - det_loss: 1.6713 - cls_loss: 1.0918 - box_loss: 0.0116 - reg_l2_loss: 0.0671 - loss: 1.7384 - learning_rate: 0.0090 - gradient_norm: 0.9606 - val_det_loss: 1.5957 - val_cls_loss: 1.0479 - val_box_loss: 0.0110 - val_reg_l2_loss: 0.0671 - val_loss: 1.6627\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 125s 465ms/step - det_loss: 1.4725 - cls_loss: 0.9688 - box_loss: 0.0101 - reg_l2_loss: 0.0670 - loss: 1.5396 - learning_rate: 0.0100 - gradient_norm: 1.3262 - val_det_loss: 1.5093 - val_cls_loss: 0.9836 - val_box_loss: 0.0105 - val_reg_l2_loss: 0.0670 - val_loss: 1.5764\n",
      "Epoch 3/50\n",
      " 97/270 [=========>....................] - ETA: 1:27 - det_loss: 1.4225 - cls_loss: 0.9336 - box_loss: 0.0098 - reg_l2_loss: 0.0670 - loss: 1.4895 - learning_rate: 0.0100 - gradient_norm: 1.4896"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mobject_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_whole_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/examples/tensorflow_examples/lite/model_maker/pip_package/src/tensorflow_examples/lite/model_maker/core/task/object_detector.py:260\u001b[0m, in \u001b[0;36mObjectDetector.create\u001b[0;34m(cls, train_data, model_spec, validation_data, epochs, batch_size, train_whole_model, do_train)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_train:\n\u001b[1;32m    259\u001b[0m   tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetraining the models...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 260\u001b[0m   \u001b[43mobject_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m   object_detector\u001b[38;5;241m.\u001b[39mcreate_model()\n",
      "File \u001b[0;32m~/examples/tensorflow_examples/lite/model_maker/pip_package/src/tensorflow_examples/lite/model_maker/core/task/object_detector.py:123\u001b[0m, in \u001b[0;36mObjectDetector.train\u001b[0;34m(self, train_data, validation_data, epochs, batch_size)\u001b[0m\n\u001b[1;32m    119\u001b[0m train_ds, steps_per_epoch, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_and_steps(\n\u001b[1;32m    120\u001b[0m     train_data, batch_size, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    121\u001b[0m validation_ds, validation_steps, val_json_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_and_steps(\n\u001b[1;32m    122\u001b[0m     validation_data, batch_size, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mvalidation_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_json_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/examples/tensorflow_examples/lite/model_maker/pip_package/src/tensorflow_examples/lite/model_maker/core/task/model_spec/object_detector_spec.py:265\u001b[0m, in \u001b[0;36mEfficientDetModelSpec.train\u001b[0;34m(self, model, train_dataset, steps_per_epoch, val_dataset, validation_steps, epochs, batch_size, val_json_file)\u001b[0m\n\u001b[1;32m    263\u001b[0m train\u001b[38;5;241m.\u001b[39msetup_model(model, config)\n\u001b[1;32m    264\u001b[0m train\u001b[38;5;241m.\u001b[39minit_experimental(config)\n\u001b[0;32m--> 265\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = object_detector.create(train_data, model_spec=spec, train_whole_model=True, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the model maker class list to a file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out this instead maybe dl new version first (did not work with old one) model.export_labels(model_dir+'/label_map.json')\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "label_map = model.model_spec.config.label_map.as_dict()\n",
    "# Writing the dictionary to a JSON file\n",
    "with open(model_dir+'/label_map.json', 'w') as file:\n",
    "    json.dump(label_map, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run tensorboard to monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=/home/alex/checkpoints_lite1_1700imgs/ --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4952ee",
   "metadata": {},
   "source": [
    "Run on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18520724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 8s 141ms/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AP': 0.08548653,\n",
       " 'AP50': 0.1361972,\n",
       " 'AP75': 0.09609742,\n",
       " 'APs': 0.0,\n",
       " 'APm': 0.055434335,\n",
       " 'APl': 0.10378562,\n",
       " 'ARmax1': 0.09282439,\n",
       " 'ARmax10': 0.16570528,\n",
       " 'ARmax100': 0.17741416,\n",
       " 'ARs': 0.0,\n",
       " 'ARm': 0.11349891,\n",
       " 'ARl': 0.20717403,\n",
       " 'AP_/other': 0.2532248,\n",
       " 'AP_/Potato': 0.12074429,\n",
       " 'AP_/Tomato': 0.15464021,\n",
       " 'AP_/Onion': 0.12620524,\n",
       " 'AP_/Apple': 0.09803807,\n",
       " 'AP_/Banana': 0.2172316,\n",
       " 'AP_/Pumpkin': 0.0325109,\n",
       " 'AP_/Scallion': 0.061618336,\n",
       " 'AP_/Avocado': 0.09182611,\n",
       " 'AP_/Lemon': 0.08666255,\n",
       " 'AP_/Bell-Pepper': 0.14741343,\n",
       " 'AP_/Carrot': 0.049910072,\n",
       " 'AP_/Egg': 0.13089462,\n",
       " 'AP_/Cucumber': 0.07713252,\n",
       " 'AP_/Zucchini': 0.044840463,\n",
       " 'AP_/Chilli': 0.0001142422,\n",
       " 'AP_/Lime': 0.03753449,\n",
       " 'AP_/Ginger': 0.08042903,\n",
       " 'AP_/Garlic': 0.041250616,\n",
       " 'AP_/Cabagge': 0.07485298,\n",
       " 'AP_/Mango': 0.0,\n",
       " 'AP_/Eggplant': 0.027572501,\n",
       " 'AP_/Broccoli': 0.0970297,\n",
       " 'AP_/Cauliflower': 0.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ae545d",
   "metadata": {},
   "source": [
    "### Export the model to tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a168367b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 22:55:52.942000: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2024-01-07 22:56:07.102552: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 3 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 1.834 G  ops, equivalently 0.917 G  MACs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 22:56:11.098355: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2024-01-07 22:56:11.098387: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2024-01-07 22:56:11.101489: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpe1doj34a\n",
      "2024-01-07 22:56:11.160670: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2024-01-07 22:56:11.160691: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmpe1doj34a\n",
      "2024-01-07 22:56:11.366282: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2024-01-07 22:56:12.367672: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpe1doj34a\n",
      "2024-01-07 22:56:12.809680: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1708856 microseconds.\n",
      "2024-01-07 22:56:13.708576: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-07 22:56:14.628536: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.834 G  ops, equivalently 0.917 G  MACs\n",
      "\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 0\n",
      "2024-01-07 22:57:25.591020: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.834 G  ops, equivalently 0.917 G  MACs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 1.834 G  ops, equivalently 0.917 G  MACs\n",
      "exported to model to models/efficientdet-lite0/model_2488_more_classes_e50_b8\n"
     ]
    }
   ],
   "source": [
    "model.export(export_dir=model_dir)\n",
    "print(f\"exported to model to {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on TFLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 254s 1s/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AP': 0.072127916,\n",
       " 'AP50': 0.112064324,\n",
       " 'AP75': 0.07951266,\n",
       " 'APs': 0.0,\n",
       " 'APm': 0.034183107,\n",
       " 'APl': 0.08941372,\n",
       " 'ARmax1': 0.06421327,\n",
       " 'ARmax10': 0.10355284,\n",
       " 'ARmax100': 0.105854,\n",
       " 'ARs': 0.0,\n",
       " 'ARm': 0.054981574,\n",
       " 'ARl': 0.12072811,\n",
       " 'AP_/Cabagge': 0.058613863,\n",
       " 'AP_/Cauliflower': 0.0,\n",
       " 'AP_/Lime': 0.025742574,\n",
       " 'AP_/other': 0.22228026,\n",
       " 'AP_/Chilli': 0.000990099,\n",
       " 'AP_/Tomato': 0.065596685,\n",
       " 'AP_/Cucumber': 0.01336198,\n",
       " 'AP_/Mango': 0.0,\n",
       " 'AP_/Lemon': 0.059609786,\n",
       " 'AP_/Bell-Pepper': 0.10160959,\n",
       " 'AP_/Carrot': 0.022990871,\n",
       " 'AP_/Onion': 0.12955928,\n",
       " 'AP_/Zucchini': 0.0016142919,\n",
       " 'AP_/Ginger': 0.15429042,\n",
       " 'AP_/Garlic': 0.062772274,\n",
       " 'AP_/Potato': 0.19233683,\n",
       " 'AP_/Scallion': 0.0071628676,\n",
       " 'AP_/Avocado': 0.0,\n",
       " 'AP_/Broccoli': 0.054455444,\n",
       " 'AP_/Pumpkin': 0.14257425,\n",
       " 'AP_/Banana': 0.15792875,\n",
       " 'AP_/Eggplant': 0.0,\n",
       " 'AP_/Egg': 0.20838435,\n",
       " 'AP_/Apple': 0.049195543}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "#model_dir='models/efficientdet-lite0/model_1907_e50_b16/model.tflite'\n",
    "model.evaluate_tflite(model_dir+'/model.tflite', test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d704b3",
   "metadata": {},
   "source": [
    "Run inference script for visual output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0344fa93",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert png image files to jpeg imgs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513fd623808d44a7a7132b50a02212a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 0\n",
      "Ignored 16196 files because: Not a PNG file\n",
      "Ignored 0 files because: Not found\n",
      "Predications will be saved to output_inference12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [04:34<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# needs to be after training for some reason\n",
    "\n",
    "%run 'png_to_jpeg.py' {annotations_base_filename +\"_mlflow_shuffled_n.csv\"}\n",
    "\n",
    "\n",
    "%run do_inference.py --input_csv {annotations_base_filename +\"_mlflow_shuffled_n.csv\"}\\\n",
    "                       --model_url {model_dir}/model.tflite --output_dir output_inference12 --label_file {model_dir}/label_map.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
