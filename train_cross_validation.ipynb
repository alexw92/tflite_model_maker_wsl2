{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Cross-Validation Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Number of unique images: 937\n",
      "Number of images: 4146\n",
      "Label Distribution:\n",
      "other          823\n",
      "Tomato         389\n",
      "Bell-Pepper    320\n",
      "Onion          302\n",
      "Garlic         237\n",
      "Potato         209\n",
      "Lemon          180\n",
      "Carrot         180\n",
      "Cucumber       169\n",
      "Egg            157\n",
      "Chilli         147\n",
      "Zucchini       142\n",
      "Apple          125\n",
      "Scallion       117\n",
      "Ginger         109\n",
      "Lime           105\n",
      "Banana          99\n",
      "Avocado         92\n",
      "Pumpkin         68\n",
      "Cabagge         64\n",
      "Eggplant        40\n",
      "Broccoli        31\n",
      "Mango           26\n",
      "Cauliflower     15\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "Fold 1:\n",
      "Number of unique images: 937\n",
      "Number of images: 4084\n",
      "Label Distribution:\n",
      "other          833\n",
      "Tomato         386\n",
      "Onion          299\n",
      "Bell-Pepper    278\n",
      "Garlic         215\n",
      "Egg            193\n",
      "Lemon          176\n",
      "Cucumber       174\n",
      "Potato         170\n",
      "Carrot         164\n",
      "Chilli         151\n",
      "Zucchini       139\n",
      "Apple          128\n",
      "Banana         122\n",
      "Scallion       120\n",
      "Ginger         101\n",
      "Lime            98\n",
      "Avocado         82\n",
      "Pumpkin         74\n",
      "Cabagge         70\n",
      "Eggplant        36\n",
      "Mango           36\n",
      "Broccoli        25\n",
      "Cauliflower     14\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "Fold 2:\n",
      "Number of unique images: 937\n",
      "Number of images: 4039\n",
      "Label Distribution:\n",
      "other          803\n",
      "Tomato         369\n",
      "Bell-Pepper    298\n",
      "Onion          266\n",
      "Garlic         203\n",
      "Potato         188\n",
      "Lemon          183\n",
      "Egg            175\n",
      "Carrot         168\n",
      "Cucumber       163\n",
      "Zucchini       154\n",
      "Apple          139\n",
      "Scallion       135\n",
      "Chilli         128\n",
      "Banana         113\n",
      "Ginger         111\n",
      "Lime           102\n",
      "Avocado         85\n",
      "Cabagge         70\n",
      "Pumpkin         65\n",
      "Eggplant        48\n",
      "Broccoli        34\n",
      "Mango           25\n",
      "Cauliflower     14\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "Fold 3:\n",
      "Number of unique images: 937\n",
      "Number of images: 4007\n",
      "Label Distribution:\n",
      "other          822\n",
      "Tomato         388\n",
      "Bell-Pepper    298\n",
      "Garlic         227\n",
      "Onion          227\n",
      "Potato         199\n",
      "Cucumber       167\n",
      "Egg            166\n",
      "Carrot         161\n",
      "Lemon          160\n",
      "Zucchini       144\n",
      "Apple          141\n",
      "Chilli         135\n",
      "Scallion       104\n",
      "Banana         104\n",
      "Ginger         103\n",
      "Lime            89\n",
      "Avocado         83\n",
      "Pumpkin         83\n",
      "Cabagge         72\n",
      "Eggplant        57\n",
      "Broccoli        35\n",
      "Mango           31\n",
      "Cauliflower     11\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "Fold 4:\n",
      "Number of unique images: 936\n",
      "Number of images: 4153\n",
      "Label Distribution:\n",
      "other          772\n",
      "Tomato         383\n",
      "Bell-Pepper    325\n",
      "Onion          264\n",
      "Garlic         215\n",
      "Potato         201\n",
      "Carrot         186\n",
      "Egg            179\n",
      "Cucumber       177\n",
      "Lemon          176\n",
      "Apple          154\n",
      "Zucchini       150\n",
      "Chilli         147\n",
      "Scallion       121\n",
      "Banana         119\n",
      "Lime           118\n",
      "Ginger         116\n",
      "Pumpkin         95\n",
      "Avocado         77\n",
      "Cabagge         64\n",
      "Broccoli        37\n",
      "Eggplant        36\n",
      "Mango           32\n",
      "Cauliflower      9\n",
      "Name: Label, dtype: int64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_240/2726608897.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_data['Split'] = 'VALIDATE'\n",
      "/tmp/ipykernel_240/2726608897.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_data['Split'] = 'VALIDATE'\n",
      "/tmp/ipykernel_240/2726608897.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_data['Split'] = 'VALIDATE'\n",
      "/tmp/ipykernel_240/2726608897.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_data['Split'] = 'VALIDATE'\n",
      "/tmp/ipykernel_240/2726608897.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_data['Split'] = 'VALIDATE'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "import argparse\n",
    "\n",
    "# Setting up command-line argument parsing\n",
    "# parser = argparse.ArgumentParser(description='Perform stratified K-Fold on object detection dataset.')\n",
    "# parser.add_argument('csv_file', type=str, help='Path to the CSV dataset file')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "csv_file = \"annotations_2488_mlflow_shuffled_n.csv\"\n",
    "# Load the dataset from the provided file path\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Correcting the column names based on your dataset format\n",
    "df.columns = ['Split', 'ImagePath', 'Label', 'Other', 'Columns', 'Not', 'Needed', 'For', 'This', 'Calculation', 'Wow']\n",
    "\n",
    "# Group by ImagePath to ensure all labels for an image stay together\n",
    "grouped = df.groupby('ImagePath')\n",
    "\n",
    "# Use the most frequent label in each image for stratification\n",
    "image_class_counts = grouped['Label'].apply(lambda x: Counter(x).most_common(1)[0][0]).reset_index(name='MostCommonLabel')\n",
    "\n",
    "# Stratified K-Fold Cross Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds = {}\n",
    "fold_files = []\n",
    "num_imgs = 0\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(image_class_counts['ImagePath'], image_class_counts['MostCommonLabel'])):\n",
    "    test_image_paths = image_class_counts.iloc[test_idx]['ImagePath'].tolist()\n",
    "    fold_data = df[df['ImagePath'].isin(test_image_paths)]\n",
    "    folds[fold] = fold_data\n",
    "    num_imgs = num_imgs + fold_data['ImagePath'].nunique()\n",
    "    # Print the distribution of each fold and the number of unique images\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"Number of unique images: {fold_data['ImagePath'].nunique()}\")\n",
    "    print(f\"Number of images: {fold_data['ImagePath'].count()}\")\n",
    "    print(\"Label Distribution:\")\n",
    "    print(fold_data['Label'].value_counts())\n",
    "    print()\n",
    "\n",
    "# Creating CSV files and calculating class distributions\n",
    "class_distributions = {}\n",
    "\n",
    "for fold, validation_data in folds.items():\n",
    "    # Combine the other folds to form the training data\n",
    "    train_data = pd.concat([folds[f] for f in folds if f != fold])\n",
    "\n",
    "    # Marking the validation and training data\n",
    "    validation_data['Split'] = 'VALIDATE'\n",
    "    train_data['Split'] = 'TRAIN'\n",
    "\n",
    "    # Combine training and validation data\n",
    "    combined_data = pd.concat([train_data, validation_data])\n",
    "\n",
    "    # Save to CSV\n",
    "    filename = f'{num_imgs}_cv_fold_{fold}.csv'\n",
    "    fold_files.append(filename)\n",
    "    combined_data.to_csv(filename, index=False, header=False)\n",
    "\n",
    "    # Collect class distributions for the validation fold\n",
    "    class_distributions[f'Fold {fold}'] = validation_data['Label'].value_counts()\n",
    "\n",
    "# Convert class distributions to a DataFrame and save\n",
    "class_distribution_df = pd.DataFrame(class_distributions)\n",
    "class_distribution_df.to_csv(f'{num_imgs}_class_distributions.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/conda_env/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.4 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training only fold number 0\n",
      "training for fold number 0 with file 4684_cv_fold_0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 23:52:24.863032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-07 23:52:24.891999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-07 23:52:24.892055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-07 23:52:24.893493: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-07 23:52:24.895147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-07 23:52:24.895206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-07 23:52:24.895250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-07 23:52:25.628682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-07 23:52:25.628755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-07 23:52:25.628762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-01-07 23:52:25.628813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-07 23:52:25.629097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21601 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 23:52:51.090177: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 151s 701ms/step - det_loss: 1.7527 - cls_loss: 1.1669 - box_loss: 0.0117 - reg_l2_loss: 0.0669 - loss: 1.8196 - learning_rate: 0.0165 - gradient_norm: 0.7187 - val_det_loss: 1.8196 - val_cls_loss: 1.3277 - val_box_loss: 0.0098 - val_reg_l2_loss: 0.0668 - val_loss: 1.8864\n",
      "Epoch 2/30\n",
      "187/187 [==============================] - 126s 676ms/step - det_loss: 1.5332 - cls_loss: 1.0152 - box_loss: 0.0104 - reg_l2_loss: 0.0668 - loss: 1.6000 - learning_rate: 0.0248 - gradient_norm: 1.0763 - val_det_loss: 1.7658 - val_cls_loss: 1.2770 - val_box_loss: 0.0098 - val_reg_l2_loss: 0.0669 - val_loss: 1.8326\n",
      "Epoch 3/30\n",
      "187/187 [==============================] - 127s 678ms/step - det_loss: 1.4078 - cls_loss: 0.9290 - box_loss: 0.0096 - reg_l2_loss: 0.0669 - loss: 1.4747 - learning_rate: 0.0245 - gradient_norm: 1.3317 - val_det_loss: 1.3545 - val_cls_loss: 0.9568 - val_box_loss: 0.0080 - val_reg_l2_loss: 0.0671 - val_loss: 1.4216\n",
      "Epoch 4/30\n",
      "187/187 [==============================] - 125s 668ms/step - det_loss: 1.3354 - cls_loss: 0.8758 - box_loss: 0.0092 - reg_l2_loss: 0.0672 - loss: 1.4026 - learning_rate: 0.0241 - gradient_norm: 1.4573 - val_det_loss: 1.5687 - val_cls_loss: 1.1734 - val_box_loss: 0.0079 - val_reg_l2_loss: 0.0673 - val_loss: 1.6360\n",
      "Epoch 5/30\n",
      "187/187 [==============================] - 155s 830ms/step - det_loss: 1.2980 - cls_loss: 0.8490 - box_loss: 0.0090 - reg_l2_loss: 0.0674 - loss: 1.3655 - learning_rate: 0.0235 - gradient_norm: 1.4945 - val_det_loss: 1.2825 - val_cls_loss: 0.8864 - val_box_loss: 0.0079 - val_reg_l2_loss: 0.0676 - val_loss: 1.3501\n",
      "Epoch 6/30\n",
      "187/187 [==============================] - 127s 676ms/step - det_loss: 1.2781 - cls_loss: 0.8346 - box_loss: 0.0089 - reg_l2_loss: 0.0677 - loss: 1.3458 - learning_rate: 0.0228 - gradient_norm: 1.5242 - val_det_loss: 1.2432 - val_cls_loss: 0.8720 - val_box_loss: 0.0074 - val_reg_l2_loss: 0.0678 - val_loss: 1.3111\n",
      "Epoch 7/30\n",
      "187/187 [==============================] - 127s 677ms/step - det_loss: 1.2442 - cls_loss: 0.8170 - box_loss: 0.0085 - reg_l2_loss: 0.0680 - loss: 1.3121 - learning_rate: 0.0220 - gradient_norm: 1.5700 - val_det_loss: 1.1733 - val_cls_loss: 0.8233 - val_box_loss: 0.0070 - val_reg_l2_loss: 0.0681 - val_loss: 1.2415\n",
      "Epoch 8/30\n",
      "187/187 [==============================] - 126s 675ms/step - det_loss: 1.2205 - cls_loss: 0.8007 - box_loss: 0.0084 - reg_l2_loss: 0.0682 - loss: 1.2887 - learning_rate: 0.0211 - gradient_norm: 1.5560 - val_det_loss: 1.1737 - val_cls_loss: 0.8344 - val_box_loss: 0.0068 - val_reg_l2_loss: 0.0683 - val_loss: 1.2421\n",
      "Epoch 9/30\n",
      "187/187 [==============================] - 126s 673ms/step - det_loss: 1.2100 - cls_loss: 0.7929 - box_loss: 0.0083 - reg_l2_loss: 0.0684 - loss: 1.2784 - learning_rate: 0.0201 - gradient_norm: 1.5969 - val_det_loss: 1.2025 - val_cls_loss: 0.8540 - val_box_loss: 0.0070 - val_reg_l2_loss: 0.0685 - val_loss: 1.2710\n",
      "Epoch 10/30\n",
      "187/187 [==============================] - 147s 789ms/step - det_loss: 1.1799 - cls_loss: 0.7737 - box_loss: 0.0081 - reg_l2_loss: 0.0686 - loss: 1.2485 - learning_rate: 0.0189 - gradient_norm: 1.6728 - val_det_loss: 1.1582 - val_cls_loss: 0.8141 - val_box_loss: 0.0069 - val_reg_l2_loss: 0.0687 - val_loss: 1.2270\n",
      "Epoch 11/30\n",
      "187/187 [==============================] - 118s 629ms/step - det_loss: 1.1645 - cls_loss: 0.7611 - box_loss: 0.0081 - reg_l2_loss: 0.0688 - loss: 1.2333 - learning_rate: 0.0177 - gradient_norm: 1.6940 - val_det_loss: 1.0986 - val_cls_loss: 0.7678 - val_box_loss: 0.0066 - val_reg_l2_loss: 0.0689 - val_loss: 1.1675\n",
      "Epoch 12/30\n",
      "187/187 [==============================] - 82s 438ms/step - det_loss: 1.1324 - cls_loss: 0.7414 - box_loss: 0.0078 - reg_l2_loss: 0.0690 - loss: 1.2014 - learning_rate: 0.0165 - gradient_norm: 1.6582 - val_det_loss: 1.0956 - val_cls_loss: 0.7741 - val_box_loss: 0.0064 - val_reg_l2_loss: 0.0690 - val_loss: 1.1647\n",
      "Epoch 13/30\n",
      "187/187 [==============================] - 83s 443ms/step - det_loss: 1.1315 - cls_loss: 0.7371 - box_loss: 0.0079 - reg_l2_loss: 0.0691 - loss: 1.2006 - learning_rate: 0.0152 - gradient_norm: 1.7718 - val_det_loss: 1.1416 - val_cls_loss: 0.8001 - val_box_loss: 0.0068 - val_reg_l2_loss: 0.0692 - val_loss: 1.2108\n",
      "Epoch 14/30\n",
      "187/187 [==============================] - 82s 441ms/step - det_loss: 1.1154 - cls_loss: 0.7244 - box_loss: 0.0078 - reg_l2_loss: 0.0692 - loss: 1.1846 - learning_rate: 0.0139 - gradient_norm: 1.7747 - val_det_loss: 1.0032 - val_cls_loss: 0.6789 - val_box_loss: 0.0065 - val_reg_l2_loss: 0.0693 - val_loss: 1.0725\n",
      "Epoch 15/30\n",
      "187/187 [==============================] - 103s 553ms/step - det_loss: 1.0820 - cls_loss: 0.7006 - box_loss: 0.0076 - reg_l2_loss: 0.0693 - loss: 1.1513 - learning_rate: 0.0125 - gradient_norm: 1.7453 - val_det_loss: 1.0178 - val_cls_loss: 0.7172 - val_box_loss: 0.0060 - val_reg_l2_loss: 0.0693 - val_loss: 1.0872\n",
      "Epoch 16/30\n",
      "187/187 [==============================] - 83s 442ms/step - det_loss: 1.0569 - cls_loss: 0.6833 - box_loss: 0.0075 - reg_l2_loss: 0.0694 - loss: 1.1262 - learning_rate: 0.0111 - gradient_norm: 1.7509 - val_det_loss: 1.0164 - val_cls_loss: 0.7146 - val_box_loss: 0.0060 - val_reg_l2_loss: 0.0694 - val_loss: 1.0858\n",
      "Epoch 17/30\n",
      "187/187 [==============================] - 83s 443ms/step - det_loss: 1.0453 - cls_loss: 0.6750 - box_loss: 0.0074 - reg_l2_loss: 0.0694 - loss: 1.1147 - learning_rate: 0.0098 - gradient_norm: 1.8181 - val_det_loss: 1.0173 - val_cls_loss: 0.7101 - val_box_loss: 0.0061 - val_reg_l2_loss: 0.0694 - val_loss: 1.0868\n",
      "Epoch 18/30\n",
      "187/187 [==============================] - 83s 443ms/step - det_loss: 1.0375 - cls_loss: 0.6691 - box_loss: 0.0074 - reg_l2_loss: 0.0694 - loss: 1.1070 - learning_rate: 0.0085 - gradient_norm: 1.8329 - val_det_loss: 0.9575 - val_cls_loss: 0.6697 - val_box_loss: 0.0058 - val_reg_l2_loss: 0.0694 - val_loss: 1.0269\n",
      "Epoch 19/30\n",
      "187/187 [==============================] - 83s 443ms/step - det_loss: 1.0170 - cls_loss: 0.6548 - box_loss: 0.0072 - reg_l2_loss: 0.0694 - loss: 1.0864 - learning_rate: 0.0073 - gradient_norm: 1.8805 - val_det_loss: 0.8571 - val_cls_loss: 0.5713 - val_box_loss: 0.0057 - val_reg_l2_loss: 0.0694 - val_loss: 0.9266\n",
      "Epoch 20/30\n",
      "187/187 [==============================] - 104s 556ms/step - det_loss: 1.0066 - cls_loss: 0.6474 - box_loss: 0.0072 - reg_l2_loss: 0.0694 - loss: 1.0761 - learning_rate: 0.0061 - gradient_norm: 1.8883 - val_det_loss: 0.9020 - val_cls_loss: 0.5991 - val_box_loss: 0.0061 - val_reg_l2_loss: 0.0694 - val_loss: 0.9714\n",
      "Epoch 21/30\n",
      "187/187 [==============================] - 83s 445ms/step - det_loss: 0.9941 - cls_loss: 0.6410 - box_loss: 0.0071 - reg_l2_loss: 0.0694 - loss: 1.0636 - learning_rate: 0.0049 - gradient_norm: 1.8746 - val_det_loss: 0.8544 - val_cls_loss: 0.5804 - val_box_loss: 0.0055 - val_reg_l2_loss: 0.0694 - val_loss: 0.9238\n",
      "Epoch 22/30\n",
      "187/187 [==============================] - 83s 442ms/step - det_loss: 0.9748 - cls_loss: 0.6288 - box_loss: 0.0069 - reg_l2_loss: 0.0694 - loss: 1.0442 - learning_rate: 0.0039 - gradient_norm: 1.8734 - val_det_loss: 0.8343 - val_cls_loss: 0.5630 - val_box_loss: 0.0054 - val_reg_l2_loss: 0.0694 - val_loss: 0.9037\n",
      "Epoch 23/30\n",
      "187/187 [==============================] - 83s 445ms/step - det_loss: 0.9690 - cls_loss: 0.6235 - box_loss: 0.0069 - reg_l2_loss: 0.0694 - loss: 1.0384 - learning_rate: 0.0030 - gradient_norm: 1.9701 - val_det_loss: 0.8211 - val_cls_loss: 0.5556 - val_box_loss: 0.0053 - val_reg_l2_loss: 0.0694 - val_loss: 0.8905\n",
      "Epoch 24/30\n",
      "187/187 [==============================] - 83s 445ms/step - det_loss: 0.9731 - cls_loss: 0.6268 - box_loss: 0.0069 - reg_l2_loss: 0.0694 - loss: 1.0425 - learning_rate: 0.0022 - gradient_norm: 1.9257 - val_det_loss: 0.8215 - val_cls_loss: 0.5438 - val_box_loss: 0.0056 - val_reg_l2_loss: 0.0694 - val_loss: 0.8909\n",
      "Epoch 25/30\n",
      "187/187 [==============================] - 105s 561ms/step - det_loss: 0.9693 - cls_loss: 0.6229 - box_loss: 0.0069 - reg_l2_loss: 0.0694 - loss: 1.0387 - learning_rate: 0.0015 - gradient_norm: 1.8511 - val_det_loss: 0.8302 - val_cls_loss: 0.5438 - val_box_loss: 0.0057 - val_reg_l2_loss: 0.0694 - val_loss: 0.8996\n",
      "Epoch 26/30\n",
      "187/187 [==============================] - 83s 445ms/step - det_loss: 0.9590 - cls_loss: 0.6182 - box_loss: 0.0068 - reg_l2_loss: 0.0694 - loss: 1.0283 - learning_rate: 8.9354e-04 - gradient_norm: 1.9118 - val_det_loss: 0.8220 - val_cls_loss: 0.5382 - val_box_loss: 0.0057 - val_reg_l2_loss: 0.0694 - val_loss: 0.8914\n",
      "Epoch 27/30\n",
      "187/187 [==============================] - 84s 448ms/step - det_loss: 0.9575 - cls_loss: 0.6169 - box_loss: 0.0068 - reg_l2_loss: 0.0694 - loss: 1.0268 - learning_rate: 4.6158e-04 - gradient_norm: 1.8681 - val_det_loss: 0.8154 - val_cls_loss: 0.5349 - val_box_loss: 0.0056 - val_reg_l2_loss: 0.0694 - val_loss: 0.8848\n",
      "Epoch 28/30\n",
      "187/187 [==============================] - 83s 442ms/step - det_loss: 0.9537 - cls_loss: 0.6148 - box_loss: 0.0068 - reg_l2_loss: 0.0694 - loss: 1.0231 - learning_rate: 1.7077e-04 - gradient_norm: 1.8478 - val_det_loss: 0.8168 - val_cls_loss: 0.5347 - val_box_loss: 0.0056 - val_reg_l2_loss: 0.0694 - val_loss: 0.8861\n",
      "Epoch 29/30\n",
      "187/187 [==============================] - 83s 443ms/step - det_loss: 0.9571 - cls_loss: 0.6156 - box_loss: 0.0068 - reg_l2_loss: 0.0694 - loss: 1.0265 - learning_rate: 2.4500e-05 - gradient_norm: 1.8452 - val_det_loss: 0.8162 - val_cls_loss: 0.5344 - val_box_loss: 0.0056 - val_reg_l2_loss: 0.0694 - val_loss: 0.8856\n",
      "Epoch 30/30\n",
      "187/187 [==============================] - 105s 560ms/step - det_loss: 0.9548 - cls_loss: 0.6145 - box_loss: 0.0068 - reg_l2_loss: 0.0694 - loss: 1.0241 - learning_rate: 2.4496e-05 - gradient_norm: 1.8670 - val_det_loss: 0.8140 - val_cls_loss: 0.5332 - val_box_loss: 0.0056 - val_reg_l2_loss: 0.0694 - val_loss: 0.8834\n",
      "47/47 [==============================] - 29s 457ms/step\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 00:45:06.813454: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2024-01-08 00:45:21.010453: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 3 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 1.834 G  ops, equivalently 0.917 G  MACs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 00:45:25.048423: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2024-01-08 00:45:25.048460: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2024-01-08 00:45:25.048970: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpthdn94b8\n",
      "2024-01-08 00:45:25.104790: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2024-01-08 00:45:25.104821: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmpthdn94b8\n",
      "2024-01-08 00:45:25.300237: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2024-01-08 00:45:26.343718: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpthdn94b8\n",
      "2024-01-08 00:45:26.802154: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1753186 microseconds.\n",
      "2024-01-08 00:45:27.677360: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-08 00:45:28.569213: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.834 G  ops, equivalently 0.917 G  MACs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 1.834 G  ops, equivalently 0.917 G  MACs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 0\n",
      "2024-01-08 00:46:39.943644: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.834 G  ops, equivalently 0.917 G  MACs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exported to model to models/efficientdet-lite0/model_2488_more_classes_plus_indiv_e30_b20_cvf_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/937 [==============================] - 1247s 1s/step\n",
      "\n",
      "skipping fold number 1\n",
      "skipping fold number 2\n",
      "skipping fold number 3\n",
      "skipping fold number 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "# The current code uses Focal loss which has already weighted loss because of alpha and gamma\n",
    "model_name = 'efficientdet-lite0' # EfficientDetLite1Spec must also be set accordingly!\n",
    "epochs = 30\n",
    "batch_size = 20\n",
    "\n",
    "train_only_fold_number = 0 \n",
    "\n",
    "fold_files = ['4684_cv_fold_0.csv','4684_cv_fold_1.csv','4684_cv_fold_2.csv','4684_cv_fold_3.csv','4684_cv_fold_4.csv']\n",
    "\n",
    "for fold_i, fold_file in enumerate(fold_files):\n",
    "    custom_model_dir_name = 'model_'+\"2488_more_classes_plus_indiv\"#str(num_distinct_files)\n",
    "    model_dir = f\"models/{model_name}/{custom_model_dir_name}_e{str(epochs)}_b{str(batch_size)}_cvf_{fold_i}\"\n",
    "    if train_only_fold_number is not None:\n",
    "        if fold_i == train_only_fold_number:\n",
    "            print(f\"training only fold number {train_only_fold_number}\")\n",
    "        else:\n",
    "            print(f\"skipping fold number {fold_i}\")\n",
    "            continue\n",
    "    print(f\"training for fold number {fold_i} with file {fold_file}\")\n",
    "    #spec = model_spec.get('efficientdet_lite1')\n",
    "    # check this url to check valid hparam values\n",
    "    # https://github.com/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/third_party/efficientdet/hparams_config.py\n",
    "    spec = object_detector.EfficientDetLite0Spec( # change this also to correct model spec\n",
    "        model_name = model_name,\n",
    "        model_dir='/home/alex/checkpoints/',\n",
    "        hparams='grad_checkpoint=true,strategy=gpus',\n",
    "        epochs=epochs, batch_size=batch_size,\n",
    "        steps_per_execution=1, moving_average_decay=0,\n",
    "        var_freeze_expr='(efficientnet|fpn_cells|resample_p6)',\n",
    "        tflite_max_detections=25\n",
    "    )\n",
    "    \n",
    "    train_data, validation_data, test_data = object_detector.DataLoader.from_csv(fold_file)\n",
    "    \n",
    "    model = object_detector.create(train_data, model_spec=spec, train_whole_model=True, validation_data=validation_data)\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    label_map = model.model_spec.config.label_map.as_dict()\n",
    "    # Writing the dictionary to a JSON file\n",
    "    with open(model_dir+'/label_map.json', 'w') as file:\n",
    "        json.dump(label_map, file)\n",
    "        \n",
    "        \n",
    "    model.evaluate(validation_data)\n",
    "    \n",
    "    model.export(export_dir=model_dir)\n",
    "    print(f\"exported to model to {model_dir}\")\n",
    "    \n",
    "    model.evaluate_tflite(model_dir+'/model.tflite', validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 27s 421ms/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AP': 0.11482489,\n",
       " 'AP50': 0.23367226,\n",
       " 'AP75': 0.10126301,\n",
       " 'APs': 0.0,\n",
       " 'APm': 0.07334023,\n",
       " 'APl': 0.13094635,\n",
       " 'ARmax1': 0.120915554,\n",
       " 'ARmax10': 0.23591745,\n",
       " 'ARmax100': 0.25812423,\n",
       " 'ARs': 0.0,\n",
       " 'ARm': 0.12904899,\n",
       " 'ARl': 0.29629952,\n",
       " 'AP_/Onion': 0.08595568,\n",
       " 'AP_/Apple': 0.07393514,\n",
       " 'AP_/Banana': 0.18724176,\n",
       " 'AP_/Pumpkin': 0.2047163,\n",
       " 'AP_/other': 0.27458826,\n",
       " 'AP_/Tomato': 0.099563606,\n",
       " 'AP_/Scallion': 0.043484483,\n",
       " 'AP_/Cucumber': 0.076655135,\n",
       " 'AP_/Lime': 0.102669716,\n",
       " 'AP_/Potato': 0.09205252,\n",
       " 'AP_/Garlic': 0.0973324,\n",
       " 'AP_/Carrot': 0.07163637,\n",
       " 'AP_/Bell-Pepper': 0.12691122,\n",
       " 'AP_/Zucchini': 0.036796402,\n",
       " 'AP_/Eggplant': 0.1459331,\n",
       " 'AP_/Chilli': 0.04162203,\n",
       " 'AP_/Lemon': 0.10796707,\n",
       " 'AP_/Avocado': 0.040056285,\n",
       " 'AP_/Mango': 0.07067793,\n",
       " 'AP_/Egg': 0.29487553,\n",
       " 'AP_/Ginger': 0.10812945,\n",
       " 'AP_/Cabagge': 0.21321613,\n",
       " 'AP_/Broccoli': 0.060286965,\n",
       " 'AP_/Cauliflower': 0.09949399}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
